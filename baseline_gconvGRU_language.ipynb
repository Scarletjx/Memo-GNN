{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.gconvGRU import GConvGRUModel\n",
    "from memory_capacity_utils import gen_lag_data_embeddings, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = np.load('../oasis_data.npy')\n",
    "# dataset = torch.from_numpy(dataset).squeeze()\n",
    "# dataset = dataset.type(torch.FloatTensor)\n",
    "# dataset = np.delete(dataset,88,axis=0)\n",
    "\n",
    "dataset = np.load(\"datasets/multivariate_simulation_data_2.npy\")\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=5, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=20, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.0001, help=\"Learninng rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90ooXFhVd5Ci"
   },
   "source": [
    "# Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "embeddings = np.load('datasets/gutenberg_embeddings.npy')\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data_embeddings(embeddings, 1000, args.max_lag, 41)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data_embeddings(embeddings, 500, args.max_lag, 42)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/real_and_predicted_graphs' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/train_losses/mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/train_losses/reservoir_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/train_losses/bio_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/train_losses/tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/train_losses/total_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/test_mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/test_tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/test_memcap_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/test_predicted' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/test_original' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gcLSTM/trained_models' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.041346488607814535, TP Loss: 2.3371906960383058\n",
      "[Validate] MAE Loss Across Timepoints: [0.04590788 0.05016259]\n",
      "[Validate] TP Loss Across Timepoints: [1.17481446 1.6991843 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.73323912 1.48277225]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.028385661222273484, TP Loss: 0.7183135610539466\n",
      "[Validate] MAE Loss Across Timepoints: [0.03459761 0.0354607 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.91304427 1.15548646]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.75001271 2.02549011]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.02543649218569044, TP Loss: 0.655409298138693\n",
      "[Validate] MAE Loss Across Timepoints: [0.03386762 0.0348905 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.87111574 1.10316646]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99788789 1.05861295]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02469104107876774, TP Loss: 0.6268129523377866\n",
      "[Validate] MAE Loss Across Timepoints: [0.03360352 0.03482043]\n",
      "[Validate] TP Loss Across Timepoints: [0.85719508 1.10119605]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94155104 1.13595768]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02424491205601953, TP Loss: 0.6103904498741031\n",
      "[Validate] MAE Loss Across Timepoints: [0.0334058  0.03465962]\n",
      "[Validate] TP Loss Across Timepoints: [0.84569031 1.08069849]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97980225 1.00625869]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.023908935210783966, TP Loss: 0.6014829711057246\n",
      "[Validate] MAE Loss Across Timepoints: [0.03324636 0.03452104]\n",
      "[Validate] TP Loss Across Timepoints: [0.84200025 1.0764972 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.09177441 1.08931483]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.023551684280391783, TP Loss: 0.5828865310177207\n",
      "[Validate] MAE Loss Across Timepoints: [0.03306757 0.0342716 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.83255208 1.05863428]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05324714 1.048653  ]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.023421598045388237, TP Loss: 0.5876863056328148\n",
      "[Validate] MAE Loss Across Timepoints: [0.03298257 0.03426621]\n",
      "[Validate] TP Loss Across Timepoints: [0.83507943 1.0671823 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03256045 1.14179014]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02323261648416519, TP Loss: 0.5795251273084432\n",
      "[Validate] MAE Loss Across Timepoints: [0.03290248 0.03416409]\n",
      "[Validate] TP Loss Across Timepoints: [0.83044791 1.05472302]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00557927 1.11671753]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.023111022863304242, TP Loss: 0.5727954145986587\n",
      "[Validate] MAE Loss Across Timepoints: [0.03285477 0.03405943]\n",
      "[Validate] TP Loss Across Timepoints: [0.82905692 1.05074   ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99986102 1.06613288]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022987121730693616, TP Loss: 0.5748262061970308\n",
      "[Validate] MAE Loss Across Timepoints: [0.03284704 0.03409851]\n",
      "[Validate] TP Loss Across Timepoints: [0.83176279 1.05654514]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.10214254 1.13983409]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.022901036718394607, TP Loss: 0.5661254427395761\n",
      "[Validate] MAE Loss Across Timepoints: [0.03275237 0.03396964]\n",
      "[Validate] TP Loss Across Timepoints: [0.81920224 1.03651321]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05268841 1.24443517]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.022802283958299085, TP Loss: 0.5645880196243525\n",
      "[Validate] MAE Loss Across Timepoints: [0.03274997 0.03402818]\n",
      "[Validate] TP Loss Across Timepoints: [0.82211214 1.04472244]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00928469 1.18606998]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02271119275246747, TP Loss: 0.5582971083931625\n",
      "[Validate] MAE Loss Across Timepoints: [0.03268513 0.03387158]\n",
      "[Validate] TP Loss Across Timepoints: [0.81150836 1.01883447]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04142648 1.11086922]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.022689341931254603, TP Loss: 0.5584374404279515\n",
      "[Validate] MAE Loss Across Timepoints: [0.03260238 0.03374204]\n",
      "[Validate] TP Loss Across Timepoints: [0.80509239 1.01257861]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98138621 1.21653898]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.022559615594218485, TP Loss: 0.5516938995569944\n",
      "[Validate] MAE Loss Across Timepoints: [0.03257141 0.03384732]\n",
      "[Validate] TP Loss Across Timepoints: [0.80598873 1.02137256]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.90117331 1.0841323 ]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.022553241986315697, TP Loss: 0.5575463441200554\n",
      "[Validate] MAE Loss Across Timepoints: [0.03246444 0.03356369]\n",
      "[Validate] TP Loss Across Timepoints: [0.78763098 0.97854656]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.9034559  1.05046553]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.022501211817143485, TP Loss: 0.5514083385933191\n",
      "[Validate] MAE Loss Across Timepoints: [0.03250915 0.03371397]\n",
      "[Validate] TP Loss Across Timepoints: [0.80143028 1.0075134 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.92595348 1.10047107]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02243187287240289, TP Loss: 0.5504465964622796\n",
      "[Validate] MAE Loss Across Timepoints: [0.03244855 0.03356951]\n",
      "[Validate] TP Loss Across Timepoints: [0.79423648 0.99231702]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.9098011  1.04554222]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.022350791841745377, TP Loss: 0.543895618757233\n",
      "[Validate] MAE Loss Across Timepoints: [0.03245611 0.03360082]\n",
      "[Validate] TP Loss Across Timepoints: [0.79934937 0.99836272]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.85024553 1.06893516]\n",
      "\n",
      "epochs finished with time:493.05822253227234\n",
      "\n",
      "Current memory usage: 2696.27 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03251389 0.03275346]\n",
      "[Test] TP Loss Across Timepoints: [0.85375366 0.87675333]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.86946313 0.90120697]\n",
      "------------------------------------Fold [2/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.038308666029479355, TP Loss: 1.830938104307279\n",
      "[Validate] MAE Loss Across Timepoints: [0.04410712 0.0488311 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.21393776 1.63933492]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.84534015 1.79416966]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.028236198806553148, TP Loss: 0.727927559055388\n",
      "[Validate] MAE Loss Across Timepoints: [0.03414045 0.03568275]\n",
      "[Validate] TP Loss Across Timepoints: [0.93788493 1.13620067]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.67503134 0.90541637]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.025103657142608427, TP Loss: 0.6514223862905055\n",
      "[Validate] MAE Loss Across Timepoints: [0.03334369 0.03501194]\n",
      "[Validate] TP Loss Across Timepoints: [0.89770699 1.09933197]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96531531 1.25763133]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.024374715765588917, TP Loss: 0.6233442034572363\n",
      "[Validate] MAE Loss Across Timepoints: [0.03314475 0.03501595]\n",
      "[Validate] TP Loss Across Timepoints: [0.89586282 1.11000133]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00848    1.38427721]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.024036302827880718, TP Loss: 0.6169247820507735\n",
      "[Validate] MAE Loss Across Timepoints: [0.03291316 0.03472269]\n",
      "[Validate] TP Loss Across Timepoints: [0.87836862 1.07882202]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00740168 1.2895296 ]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.023714391456451267, TP Loss: 0.6041663775686175\n",
      "[Validate] MAE Loss Across Timepoints: [0.0327398  0.03449633]\n",
      "[Validate] TP Loss Across Timepoints: [0.86655307 1.06119812]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.84712543 1.1338637 ]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02353292767656967, TP Loss: 0.6023905833717436\n",
      "[Validate] MAE Loss Across Timepoints: [0.03262115 0.0342599 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.85596913 1.03633213]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.88608572 1.08378685]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.02336255769478157, TP Loss: 0.6010464080609381\n",
      "[Validate] MAE Loss Across Timepoints: [0.03260363 0.03422985]\n",
      "[Validate] TP Loss Across Timepoints: [0.8606593  1.04080248]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.89756754 1.07448128]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.023178676710813306, TP Loss: 0.5821425943868235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.03253255 0.0340913 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.85487193 1.0270617 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94025923 1.10204481]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.023082637519109994, TP Loss: 0.5843747139442712\n",
      "[Validate] MAE Loss Across Timepoints: [0.03253138 0.03405628]\n",
      "[Validate] TP Loss Across Timepoints: [0.85872126 1.03144455]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94911675 1.10497623]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.023030587210087106, TP Loss: 0.5856832597637549\n",
      "[Validate] MAE Loss Across Timepoints: [0.03251737 0.03401599]\n",
      "[Validate] TP Loss Across Timepoints: [0.86087114 1.03096735]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01071243 1.0981164 ]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02286619012011215, TP Loss: 0.5802995344856754\n",
      "[Validate] MAE Loss Across Timepoints: [0.03242958 0.03391805]\n",
      "[Validate] TP Loss Across Timepoints: [0.85158288 1.0190258 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99609319 1.11445965]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.02283125692338217, TP Loss: 0.5837264023721218\n",
      "[Validate] MAE Loss Across Timepoints: [0.03238572 0.0338504 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.8425433  1.00194752]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97023901 1.07314927]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.022717359330272302, TP Loss: 0.5746047749416903\n",
      "[Validate] MAE Loss Across Timepoints: [0.03236604 0.03386285]\n",
      "[Validate] TP Loss Across Timepoints: [0.84463882 1.00855827]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97596016 1.12062107]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.022636472043814138, TP Loss: 0.5677365090232342\n",
      "[Validate] MAE Loss Across Timepoints: [0.03235473 0.03383221]\n",
      "[Validate] TP Loss Across Timepoints: [0.84859562 1.01454496]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96456316 1.15554627]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02266674509155564, TP Loss: 0.5807466574478894\n",
      "[Validate] MAE Loss Across Timepoints: [0.03228935 0.03373877]\n",
      "[Validate] TP Loss Across Timepoints: [0.84165013 1.00051546]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.89324765 1.05262077]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.022560481098480523, TP Loss: 0.5752559597603977\n",
      "[Validate] MAE Loss Across Timepoints: [0.03224815 0.03374925]\n",
      "[Validate] TP Loss Across Timepoints: [0.83964574 0.99940795]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.90654877 1.06733167]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.022519314341479912, TP Loss: 0.5667787902057171\n",
      "[Validate] MAE Loss Across Timepoints: [0.03220474 0.03369142]\n",
      "[Validate] TP Loss Across Timepoints: [0.83808875 0.99903303]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.82865285 1.17804252]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.022424582653911784, TP Loss: 0.5630104870069772\n",
      "[Validate] MAE Loss Across Timepoints: [0.03220507 0.03368739]\n",
      "[Validate] TP Loss Across Timepoints: [0.83949959 1.00152266]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.88107516 1.23890404]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.022381615897757, TP Loss: 0.5602936840150505\n",
      "[Validate] MAE Loss Across Timepoints: [0.03212537 0.03363198]\n",
      "[Validate] TP Loss Across Timepoints: [0.82913029 0.98387831]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.84831578 1.18553792]\n",
      "\n",
      "epochs finished with time:493.3144187927246\n",
      "\n",
      "Current memory usage: 2697.43 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03171845 0.03304491]\n",
      "[Test] TP Loss Across Timepoints: [0.63731794 0.88781471]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [1.01182421 1.05026915]\n",
      "------------------------------------Fold [3/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.04095116467215121, TP Loss: 2.1505688978359103\n",
      "[Validate] MAE Loss Across Timepoints: [0.05208727 0.05735503]\n",
      "[Validate] TP Loss Across Timepoints: [1.68168676 2.55510068]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53684218 0.79879368]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.03027968475362286, TP Loss: 0.7969592832960188\n",
      "[Validate] MAE Loss Across Timepoints: [0.03681079 0.03899042]\n",
      "[Validate] TP Loss Across Timepoints: [0.98655558 1.31918347]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.5517313  0.41459679]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.02535045771219302, TP Loss: 0.6393559870775789\n",
      "[Validate] MAE Loss Across Timepoints: [0.03441794 0.03595498]\n",
      "[Validate] TP Loss Across Timepoints: [0.91369784 1.17895615]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01469191 1.00424704]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.024367700272705406, TP Loss: 0.6126431715674698\n",
      "[Validate] MAE Loss Across Timepoints: [0.03422174 0.03584128]\n",
      "[Validate] TP Loss Across Timepoints: [0.90750152 1.16406631]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.83392199 0.88354864]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02390163175005, TP Loss: 0.5949079026468098\n",
      "[Validate] MAE Loss Across Timepoints: [0.03399301 0.0355967 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.89547646 1.14502847]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.80545922 0.76643357]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.023616713151568547, TP Loss: 0.5785875489236787\n",
      "[Validate] MAE Loss Across Timepoints: [0.03386799 0.03542612]\n",
      "[Validate] TP Loss Across Timepoints: [0.89158219 1.13226712]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.92930515 0.80633332]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.023359335275017656, TP Loss: 0.5750880662817508\n",
      "[Validate] MAE Loss Across Timepoints: [0.03384595 0.03541819]\n",
      "[Validate] TP Loss Across Timepoints: [0.89903635 1.14258337]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94222986 0.74634588]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.023180543445050716, TP Loss: 0.5667739063501358\n",
      "[Validate] MAE Loss Across Timepoints: [0.03367225 0.03515741]\n",
      "[Validate] TP Loss Across Timepoints: [0.88436341 1.11264181]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.88880557 0.74279309]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02305603575950954, TP Loss: 0.5672822271008044\n",
      "[Validate] MAE Loss Across Timepoints: [0.03361142 0.03504293]\n",
      "[Validate] TP Loss Across Timepoints: [0.88398153 1.11076498]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.90657101 0.77435971]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.022926792851649225, TP Loss: 0.5580934195313603\n",
      "[Validate] MAE Loss Across Timepoints: [0.0335457  0.03489866]\n",
      "[Validate] TP Loss Across Timepoints: [0.88109916 1.10166287]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.0006504  0.83353256]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022772275682655163, TP Loss: 0.5502426458988339\n",
      "[Validate] MAE Loss Across Timepoints: [0.03352084 0.03483659]\n",
      "[Validate] TP Loss Across Timepoints: [0.88067001 1.09959221]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99322788 0.71672864]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.022733373698429205, TP Loss: 0.5488216718658805\n",
      "[Validate] MAE Loss Across Timepoints: [0.0335107  0.03486032]\n",
      "[Validate] TP Loss Across Timepoints: [0.88187069 1.09945107]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96432205 0.79281315]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.022662250034045428, TP Loss: 0.5546823805198073\n",
      "[Validate] MAE Loss Across Timepoints: [0.03345682 0.0347275 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.87969226 1.09301877]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.01355056 0.88964839]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02262915502069518, TP Loss: 0.5542347051668912\n",
      "[Validate] MAE Loss Across Timepoints: [0.03325067 0.0344472 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.84741116 1.0431174 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.06992747 0.90417493]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.022502050138427876, TP Loss: 0.5490062054013833\n",
      "[Validate] MAE Loss Across Timepoints: [0.03337822 0.03463071]\n",
      "[Validate] TP Loss Across Timepoints: [0.87557346 1.08818543]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04071154 0.86320417]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.022562402358744293, TP Loss: 0.5531666963361204\n",
      "[Validate] MAE Loss Across Timepoints: [0.03330908 0.03454005]\n",
      "[Validate] TP Loss Across Timepoints: [0.86584878 1.07178545]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04744491 0.91952513]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.02243804644967895, TP Loss: 0.5426091473782435\n",
      "[Validate] MAE Loss Across Timepoints: [0.03330285 0.03451855]\n",
      "[Validate] TP Loss Across Timepoints: [0.86549127 1.07136798]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.07291006 0.95688973]\n",
      "Epoch [18/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.022329080413328484, TP Loss: 0.541023432626389\n",
      "[Validate] MAE Loss Across Timepoints: [0.03325804 0.0344383 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.86267209 1.06039357]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02961819 0.79337644]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.022272701680776663, TP Loss: 0.5363331704866141\n",
      "[Validate] MAE Loss Across Timepoints: [0.03326665 0.03449034]\n",
      "[Validate] TP Loss Across Timepoints: [0.8689273  1.07260144]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.0349199  0.95288363]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02230743745167274, TP Loss: 0.5423625697148964\n",
      "[Validate] MAE Loss Across Timepoints: [0.03324124 0.0343751 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.86383152 1.0622648 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03254208 1.04741051]\n",
      "\n",
      "epochs finished with time:494.5947012901306\n",
      "\n",
      "Current memory usage: 2697.80 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03147686 0.03394839]\n",
      "[Test] TP Loss Across Timepoints: [0.77880387 0.99710197]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [1.0315216  1.09002792]\n",
      "------------------------------------Fold [4/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.0444452106312383, TP Loss: 2.878763839136809\n",
      "[Validate] MAE Loss Across Timepoints: [0.05066252 0.05655409]\n",
      "[Validate] TP Loss Across Timepoints: [1.50130677 2.60949612]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65707857 0.55146192]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.030048247732338496, TP Loss: 0.7754480734001845\n",
      "[Validate] MAE Loss Across Timepoints: [0.03431541 0.03596987]\n",
      "[Validate] TP Loss Across Timepoints: [0.85931063 1.10045958]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.73613787 0.76797441]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.02537838638818357, TP Loss: 0.6525658911559731\n",
      "[Validate] MAE Loss Across Timepoints: [0.03332906 0.03473514]\n",
      "[Validate] TP Loss Across Timepoints: [0.83546168 1.06564641]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00355172 0.92766436]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.02454617148032412, TP Loss: 0.6310743665089831\n",
      "[Validate] MAE Loss Across Timepoints: [0.0330788  0.03449602]\n",
      "[Validate] TP Loss Across Timepoints: [0.82862651 1.05640972]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02936323 1.02926461]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.02414753765333444, TP Loss: 0.6181021560914814\n",
      "[Validate] MAE Loss Across Timepoints: [0.03292078 0.03424228]\n",
      "[Validate] TP Loss Across Timepoints: [0.81831485 1.02493286]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.09893944 1.05814356]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.023810135913663544, TP Loss: 0.6121296777855605\n",
      "[Validate] MAE Loss Across Timepoints: [0.03278402 0.03386242]\n",
      "[Validate] TP Loss Across Timepoints: [0.80401123 0.9813289 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.16718589 1.02082059]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.023516493805800565, TP Loss: 0.5956954832654446\n",
      "[Validate] MAE Loss Across Timepoints: [0.03271067 0.03366763]\n",
      "[Validate] TP Loss Across Timepoints: [0.79818892 0.95784128]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.22803317 1.06854977]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.02333167642063927, TP Loss: 0.5890709009254351\n",
      "[Validate] MAE Loss Across Timepoints: [0.03271006 0.03383975]\n",
      "[Validate] TP Loss Across Timepoints: [0.80750328 0.99468982]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.21191283 1.02811972]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.02332298195688054, TP Loss: 0.597105696098879\n",
      "[Validate] MAE Loss Across Timepoints: [0.03262969 0.03361847]\n",
      "[Validate] TP Loss Across Timepoints: [0.7968812 0.9609217]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.16425814 1.04699543]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.023170332176960073, TP Loss: 0.594948320183903\n",
      "[Validate] MAE Loss Across Timepoints: [0.03259661 0.03358995]\n",
      "[Validate] TP Loss Across Timepoints: [0.79819936 0.96693921]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.18519179 1.04298559]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022969510522671044, TP Loss: 0.5761679873103276\n",
      "[Validate] MAE Loss Across Timepoints: [0.03255341 0.03355632]\n",
      "[Validate] TP Loss Across Timepoints: [0.79427904 0.96362275]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.12591544 1.11489127]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.022863499747472815, TP Loss: 0.5745912214042619\n",
      "[Validate] MAE Loss Across Timepoints: [0.03251036 0.0335355 ]\n",
      "[Validate] TP Loss Across Timepoints: [0.79186356 0.96311772]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02807345 1.06612233]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.02287359643378295, TP Loss: 0.5716158902505413\n",
      "[Validate] MAE Loss Across Timepoints: [0.03248392 0.03344796]\n",
      "[Validate] TP Loss Across Timepoints: [0.7891053 0.9508118]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03000804 1.16567868]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02268680492124986, TP Loss: 0.5692564491182566\n",
      "[Validate] MAE Loss Across Timepoints: [0.03243501 0.03330684]\n",
      "[Validate] TP Loss Across Timepoints: [0.78432369 0.93606997]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.07162466 1.15625823]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.022693310209433548, TP Loss: 0.5717576519818977\n",
      "[Validate] MAE Loss Across Timepoints: [0.03238928 0.03329782]\n",
      "[Validate] TP Loss Across Timepoints: [0.78367096 0.93759096]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00340974 1.14881592]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.02255782121210359, TP Loss: 0.5608909288421273\n",
      "[Validate] MAE Loss Across Timepoints: [0.0323537  0.03331606]\n",
      "[Validate] TP Loss Across Timepoints: [0.78384984 0.94129646]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00554556 1.12854768]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.022572431465960108, TP Loss: 0.5703971991315484\n",
      "[Validate] MAE Loss Across Timepoints: [0.03227515 0.03318227]\n",
      "[Validate] TP Loss Across Timepoints: [0.77585489 0.92390805]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.9868356  1.01197189]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.022482984117232263, TP Loss: 0.55874157208018\n",
      "[Validate] MAE Loss Across Timepoints: [0.03224785 0.03314937]\n",
      "[Validate] TP Loss Across Timepoints: [0.77538139 0.92201698]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98881333 1.01435273]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02247789611283224, TP Loss: 0.5642265160568058\n",
      "[Validate] MAE Loss Across Timepoints: [0.03224468 0.03327772]\n",
      "[Validate] TP Loss Across Timepoints: [0.78097975 0.94427311]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96459741 1.06400595]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.02243236631329637, TP Loss: 0.5639107676688582\n",
      "[Validate] MAE Loss Across Timepoints: [0.03217773 0.03318128]\n",
      "[Validate] TP Loss Across Timepoints: [0.7745865 0.930574 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96930698 0.98322551]\n",
      "\n",
      "epochs finished with time:490.1586890220642\n",
      "\n",
      "Current memory usage: 2697.71 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03154615 0.03421176]\n",
      "[Test] TP Loss Across Timepoints: [0.74431033 0.96060181]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.83396854 1.27752974]\n",
      "------------------------------------Fold [5/5]-----------------------------------------\n",
      "Epoch [1/20]\n",
      "[Train] MAE Loss: 0.037492746123461984, TP Loss: 1.7697511203587055\n",
      "[Validate] MAE Loss Across Timepoints: [0.04268108 0.05003444]\n",
      "[Validate] TP Loss Across Timepoints: [1.20978892 1.7475543 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52788555 0.85385772]\n",
      "Epoch [2/20]\n",
      "[Train] MAE Loss: 0.02729207437369041, TP Loss: 0.7111372444778681\n",
      "[Validate] MAE Loss Across Timepoints: [0.03338221 0.03589113]\n",
      "[Validate] TP Loss Across Timepoints: [0.86168706 1.1651727 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.78176683 0.74159943]\n",
      "Epoch [3/20]\n",
      "[Train] MAE Loss: 0.024516791178029962, TP Loss: 0.6060710590099916\n",
      "[Validate] MAE Loss Across Timepoints: [0.03269299 0.03503156]\n",
      "[Validate] TP Loss Across Timepoints: [0.81013554 1.08429766]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.89733825 0.85675368]\n",
      "Epoch [4/20]\n",
      "[Train] MAE Loss: 0.023894065234344453, TP Loss: 0.5828603744739667\n",
      "[Validate] MAE Loss Across Timepoints: [0.03234239 0.03460693]\n",
      "[Validate] TP Loss Across Timepoints: [0.7870428  1.04198766]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.89408643 0.92358538]\n",
      "Epoch [5/20]\n",
      "[Train] MAE Loss: 0.023544403447885998, TP Loss: 0.5779204657301307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.03219732 0.03450734]\n",
      "[Validate] TP Loss Across Timepoints: [0.78871852 1.04886603]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.05376936 0.92936932]\n",
      "Epoch [6/20]\n",
      "[Train] MAE Loss: 0.02321353532897774, TP Loss: 0.5591316969366744\n",
      "[Validate] MAE Loss Across Timepoints: [0.03207136 0.03414758]\n",
      "[Validate] TP Loss Across Timepoints: [0.77677017 1.01518583]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98492568 0.94750406]\n",
      "Epoch [7/20]\n",
      "[Train] MAE Loss: 0.02298994177544955, TP Loss: 0.5559555895160884\n",
      "[Validate] MAE Loss Across Timepoints: [0.03199917 0.03406509]\n",
      "[Validate] TP Loss Across Timepoints: [0.77509826 1.01192904]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.99924944 0.92504098]\n",
      "Epoch [8/20]\n",
      "[Train] MAE Loss: 0.022852072710520588, TP Loss: 0.5473553922493011\n",
      "[Validate] MAE Loss Across Timepoints: [0.03196625 0.03390761]\n",
      "[Validate] TP Loss Across Timepoints: [0.77186394 0.99954873]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.95927406 0.95055498]\n",
      "Epoch [9/20]\n",
      "[Train] MAE Loss: 0.022716239109286107, TP Loss: 0.541995394974947\n",
      "[Validate] MAE Loss Across Timepoints: [0.0318963  0.03380731]\n",
      "[Validate] TP Loss Across Timepoints: [0.76639324 0.98795861]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00074383 1.01496632]\n",
      "Epoch [10/20]\n",
      "[Train] MAE Loss: 0.02265062279184349, TP Loss: 0.547367159393616\n",
      "[Validate] MAE Loss Across Timepoints: [0.03188612 0.03382838]\n",
      "[Validate] TP Loss Across Timepoints: [0.76958936 0.99641347]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98058708 0.97315051]\n",
      "Epoch [11/20]\n",
      "[Train] MAE Loss: 0.022530413436470553, TP Loss: 0.5405166967539117\n",
      "[Validate] MAE Loss Across Timepoints: [0.0318093  0.03373885]\n",
      "[Validate] TP Loss Across Timepoints: [0.7630133  0.98636019]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02568731 1.12369743]\n",
      "Epoch [12/20]\n",
      "[Train] MAE Loss: 0.02252231806050986, TP Loss: 0.5465572110842913\n",
      "[Validate] MAE Loss Across Timepoints: [0.03177924 0.03374548]\n",
      "[Validate] TP Loss Across Timepoints: [0.76246548 0.98702967]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00179296 1.07561871]\n",
      "Epoch [13/20]\n",
      "[Train] MAE Loss: 0.02241136902011931, TP Loss: 0.5365970311686397\n",
      "[Validate] MAE Loss Across Timepoints: [0.03173566 0.03367493]\n",
      "[Validate] TP Loss Across Timepoints: [0.76156396 0.9859218 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.98590267 1.06332392]\n",
      "Epoch [14/20]\n",
      "[Train] MAE Loss: 0.02233086536580231, TP Loss: 0.5347226258600131\n",
      "[Validate] MAE Loss Across Timepoints: [0.03170744 0.03365726]\n",
      "[Validate] TP Loss Across Timepoints: [0.76034772 0.98364556]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.89995368 0.97872353]\n",
      "Epoch [15/20]\n",
      "[Train] MAE Loss: 0.022227804525755346, TP Loss: 0.5273262246046215\n",
      "[Validate] MAE Loss Across Timepoints: [0.0316283  0.03348404]\n",
      "[Validate] TP Loss Across Timepoints: [0.75059444 0.95498037]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.85876265 0.98149416]\n",
      "Epoch [16/20]\n",
      "[Train] MAE Loss: 0.022260941739659756, TP Loss: 0.5320146897574887\n",
      "[Validate] MAE Loss Across Timepoints: [0.03164417 0.03357921]\n",
      "[Validate] TP Loss Across Timepoints: [0.75651765 0.97085381]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.87003117 0.91750995]\n",
      "Epoch [17/20]\n",
      "[Train] MAE Loss: 0.022155355123686604, TP Loss: 0.5282936280127615\n",
      "[Validate] MAE Loss Across Timepoints: [0.03161048 0.03357005]\n",
      "[Validate] TP Loss Across Timepoints: [0.75840873 0.97700596]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.82682834 0.88056368]\n",
      "Epoch [18/20]\n",
      "[Train] MAE Loss: 0.02216664794832468, TP Loss: 0.5298715379321948\n",
      "[Validate] MAE Loss Across Timepoints: [0.0315702  0.03353333]\n",
      "[Validate] TP Loss Across Timepoints: [0.75707263 0.97453249]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.79179939 0.94589222]\n",
      "Epoch [19/20]\n",
      "[Train] MAE Loss: 0.02210159521200694, TP Loss: 0.5294118149904534\n",
      "[Validate] MAE Loss Across Timepoints: [0.03151661 0.03340073]\n",
      "[Validate] TP Loss Across Timepoints: [0.75135976 0.96138972]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.76613729 0.97403237]\n",
      "Epoch [20/20]\n",
      "[Train] MAE Loss: 0.022039581352146342, TP Loss: 0.5266153502743691\n",
      "[Validate] MAE Loss Across Timepoints: [0.03148497 0.03335707]\n",
      "[Validate] TP Loss Across Timepoints: [0.74840522 0.95624393]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.77872961 0.94962264]\n",
      "\n",
      "epochs finished with time:491.37079310417175\n",
      "\n",
      "Current memory usage: 2697.21 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03406277 0.03363521]\n",
      "[Test] TP Loss Across Timepoints: [0.87290802 0.91101904]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.90166545 0.70147763]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_2_language.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    # Create model instance\n",
    "    model = GConvGRUModel(device=device, input_weights=input_weights, input_scaling=1e-1).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1): \n",
    "                pred = model(data[t])\n",
    "                real = data[t + 1]\n",
    "                # print(pred)\n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss\n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap,\n",
    "                                                                                            X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
