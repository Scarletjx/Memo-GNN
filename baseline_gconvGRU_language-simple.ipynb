{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.gconvGRU_simple import GConvGRUModel\n",
    "from memory_capacity_utils import gen_lag_data_embeddings, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('datasets/oasis_data.npy')\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)\n",
    "dataset = np.delete(dataset,88,axis=0)\n",
    "\n",
    "# dataset = np.load(\"datasets/multivariate_simulation_data_2.npy\")\n",
    "# dataset = torch.from_numpy(dataset).squeeze()\n",
    "# dataset = dataset.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=3, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=25, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help=\"Learning rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "embeddings = np.load('datasets/gutenberg_embeddings.npy')\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data_embeddings(embeddings, 1000, args.max_lag, 41)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data_embeddings(embeddings, 500, args.max_lag, 42)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/real_and_predicted_graphs' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/train_losses/mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/train_losses/reservoir_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/train_losses/bio_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/train_losses/tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/train_losses/total_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/test_mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/test_tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/test_memcap_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/test_predicted' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/test_original' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/baseline_gconvGRU_language_2/trained_models' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/3]-----------------------------------------\n",
      "Epoch [1/25]\n",
      "[Train] MAE Loss: 0.05095640538881222, TP Loss: 3.3975850254297257\n",
      "[Validate] MAE Loss Across Timepoints: [0.0768441  0.06443176]\n",
      "[Validate] TP Loss Across Timepoints: [11.12688293  2.19567998]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57337221 0.71241179]\n",
      "Epoch [2/25]\n",
      "[Train] MAE Loss: 0.04335717642679811, TP Loss: 2.758782848715782\n",
      "[Validate] MAE Loss Across Timepoints: [0.06538308 0.05361247]\n",
      "[Validate] TP Loss Across Timepoints: [9.30393982 1.55640043]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52840852 0.57151708]\n",
      "Epoch [3/25]\n",
      "[Train] MAE Loss: 0.03859871405487259, TP Loss: 2.330310787508885\n",
      "[Validate] MAE Loss Across Timepoints: [0.0616601  0.04969955]\n",
      "[Validate] TP Loss Across Timepoints: [8.82451782 1.39674555]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52233398 0.65552041]\n",
      "Epoch [4/25]\n",
      "[Train] MAE Loss: 0.035921758382270734, TP Loss: 2.16670040016373\n",
      "[Validate] MAE Loss Across Timepoints: [0.05743746 0.04439486]\n",
      "[Validate] TP Loss Across Timepoints: [8.13738658 1.18303439]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.81723158 0.57889641]\n",
      "Epoch [5/25]\n",
      "[Train] MAE Loss: 0.0342186890852948, TP Loss: 2.037537960956494\n",
      "[Validate] MAE Loss Across Timepoints: [0.05714628 0.04343969]\n",
      "[Validate] TP Loss Across Timepoints: [8.21480103 1.24204839]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57028933 1.12891468]\n",
      "Epoch [6/25]\n",
      "[Train] MAE Loss: 0.03369538780922691, TP Loss: 2.0639264645675817\n",
      "[Validate] MAE Loss Across Timepoints: [0.05658417 0.04252341]\n",
      "[Validate] TP Loss Across Timepoints: [8.09201711 1.16057281]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60504575 1.08728277]\n",
      "Epoch [7/25]\n",
      "[Train] MAE Loss: 0.03357745974014203, TP Loss: 2.0576879411935804\n",
      "[Validate] MAE Loss Across Timepoints: [0.05643839 0.04229386]\n",
      "[Validate] TP Loss Across Timepoints: [8.04431559 1.14597664]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66403141 0.61594209]\n",
      "Epoch [8/25]\n",
      "[Train] MAE Loss: 0.03323704339563847, TP Loss: 1.997407293568055\n",
      "[Validate] MAE Loss Across Timepoints: [0.05640287 0.04240207]\n",
      "[Validate] TP Loss Across Timepoints: [8.04545593 1.15484632]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61031395 0.58209466]\n",
      "Epoch [9/25]\n",
      "[Train] MAE Loss: 0.0331799052345256, TP Loss: 2.05340911000967\n",
      "[Validate] MAE Loss Across Timepoints: [0.05617779 0.04209629]\n",
      "[Validate] TP Loss Across Timepoints: [7.99280599 1.10490583]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.65151253 0.67080057]\n",
      "Epoch [10/25]\n",
      "[Train] MAE Loss: 0.032905579234162964, TP Loss: 2.0170143499970434\n",
      "[Validate] MAE Loss Across Timepoints: [0.05608178 0.04204702]\n",
      "[Validate] TP Loss Across Timepoints: [7.95369568 1.07527631]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61168592 1.58981274]\n",
      "Epoch [11/25]\n",
      "[Train] MAE Loss: 0.0329257767337064, TP Loss: 1.9918302237987517\n",
      "[Validate] MAE Loss Across Timepoints: [0.05586258 0.04183775]\n",
      "[Validate] TP Loss Across Timepoints: [7.96839549 1.08900261]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6657921  0.53411897]\n",
      "Epoch [12/25]\n",
      "[Train] MAE Loss: 0.032815254448602595, TP Loss: 2.015887189408143\n",
      "[Validate] MAE Loss Across Timepoints: [0.0558037  0.04180771]\n",
      "[Validate] TP Loss Across Timepoints: [7.95398966 1.07535439]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.69760491 0.61790227]\n",
      "Epoch [13/25]\n",
      "[Train] MAE Loss: 0.03258452241619428, TP Loss: 2.022790619979302\n",
      "[Validate] MAE Loss Across Timepoints: [0.05598776 0.04182652]\n",
      "[Validate] TP Loss Across Timepoints: [8.03155314 1.09418577]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.69404972 0.55029996]\n",
      "Epoch [14/25]\n",
      "[Train] MAE Loss: 0.03248940429960688, TP Loss: 1.9404941283166408\n",
      "[Validate] MAE Loss Across Timepoints: [0.05571026 0.04173127]\n",
      "[Validate] TP Loss Across Timepoints: [7.91114197 1.05304356]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6485926 0.5887559]\n",
      "Epoch [15/25]\n",
      "[Train] MAE Loss: 0.03259398468459646, TP Loss: 1.980823411544164\n",
      "[Validate] MAE Loss Across Timepoints: [0.05567828 0.04167977]\n",
      "[Validate] TP Loss Across Timepoints: [7.89930064 1.0437205 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.71842135 0.56492243]\n",
      "Epoch [16/25]\n",
      "[Train] MAE Loss: 0.03259423940132062, TP Loss: 2.0016907234986623\n",
      "[Validate] MAE Loss Across Timepoints: [0.05574428 0.04171024]\n",
      "[Validate] TP Loss Across Timepoints: [7.92815247 1.04379196]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66777485 0.54199159]\n",
      "Epoch [17/25]\n",
      "[Train] MAE Loss: 0.0324902883109947, TP Loss: 1.9872806288301945\n",
      "[Validate] MAE Loss Across Timepoints: [0.05572184 0.04173781]\n",
      "[Validate] TP Loss Across Timepoints: [7.93438772 1.02809003]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66515307 0.56607506]\n",
      "Epoch [18/25]\n",
      "[Train] MAE Loss: 0.03238621155420939, TP Loss: 1.9537630965312323\n",
      "[Validate] MAE Loss Across Timepoints: [0.0557585 0.0416694]\n",
      "[Validate] TP Loss Across Timepoints: [7.99463959 1.07999598]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.67226966 0.60276429]\n",
      "Epoch [19/25]\n",
      "[Train] MAE Loss: 0.03243011835341652, TP Loss: 2.0030262085298696\n",
      "[Validate] MAE Loss Across Timepoints: [0.05578307 0.04166351]\n",
      "[Validate] TP Loss Across Timepoints: [7.98848775 1.05184161]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6701821  0.59401222]\n",
      "Epoch [20/25]\n",
      "[Train] MAE Loss: 0.03226821348071098, TP Loss: 1.9647712849080563\n",
      "[Validate] MAE Loss Across Timepoints: [0.0556422  0.04156943]\n",
      "[Validate] TP Loss Across Timepoints: [7.97334391 1.06970774]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6670072  0.53790839]\n",
      "Epoch [21/25]\n",
      "[Train] MAE Loss: 0.03233366074661414, TP Loss: 1.9655002129574617\n",
      "[Validate] MAE Loss Across Timepoints: [0.05582591 0.04166635]\n",
      "[Validate] TP Loss Across Timepoints: [8.05241801 1.08124835]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.74232379 0.56320643]\n",
      "Epoch [22/25]\n",
      "[Train] MAE Loss: 0.032347478438168764, TP Loss: 1.9742676198482514\n",
      "[Validate] MAE Loss Across Timepoints: [0.05559143 0.04159297]\n",
      "[Validate] TP Loss Across Timepoints: [7.96604309 1.05681318]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.80958143 0.51567571]\n",
      "Epoch [23/25]\n",
      "[Train] MAE Loss: 0.03222868017231425, TP Loss: 1.9770558287700017\n",
      "[Validate] MAE Loss Across Timepoints: [0.05568478 0.04156433]\n",
      "[Validate] TP Loss Across Timepoints: [7.9598231  1.03737132]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.77038795 0.62002554]\n",
      "Epoch [24/25]\n",
      "[Train] MAE Loss: 0.032197600789368154, TP Loss: 1.951288146028916\n",
      "[Validate] MAE Loss Across Timepoints: [0.0555347  0.04155865]\n",
      "[Validate] TP Loss Across Timepoints: [7.95247854 1.04102942]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.78770561 0.53706398]\n",
      "Epoch [25/25]\n",
      "[Train] MAE Loss: 0.03220271421596408, TP Loss: 1.9475449132422606\n",
      "[Validate] MAE Loss Across Timepoints: [0.05549688 0.04148914]\n",
      "[Validate] TP Loss Across Timepoints: [7.94794718 1.03636322]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.79981078 0.49716133]\n",
      "\n",
      "epochs finished with time:240.83289074897766\n",
      "\n",
      "Current memory usage: 2627.64 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04018998 0.04477156]\n",
      "[Test] TP Loss Across Timepoints: [1.20082102 1.80171906]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.83540064 0.6367481 ]\n",
      "------------------------------------Fold [2/3]-----------------------------------------\n",
      "Epoch [1/25]\n",
      "[Train] MAE Loss: 0.04792863987386227, TP Loss: 2.9947997788588205\n",
      "[Validate] MAE Loss Across Timepoints: [0.073757   0.06894761]\n",
      "[Validate] TP Loss Across Timepoints: [11.24828695  4.33285065]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.66749423 1.40524229]\n",
      "Epoch [2/25]\n",
      "[Train] MAE Loss: 0.04126591046030323, TP Loss: 2.425933184723059\n",
      "[Validate] MAE Loss Across Timepoints: [0.0652638  0.06168317]\n",
      "[Validate] TP Loss Across Timepoints: [9.82407837 3.63420995]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62110019 0.7885782 ]\n",
      "Epoch [3/25]\n",
      "[Train] MAE Loss: 0.03723923886815707, TP Loss: 1.947940429051717\n",
      "[Validate] MAE Loss Across Timepoints: [0.06085454 0.05646833]\n",
      "[Validate] TP Loss Across Timepoints: [8.98752848 3.15560888]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.55855286 0.71109431]\n",
      "Epoch [4/25]\n",
      "[Train] MAE Loss: 0.035113989779104786, TP Loss: 1.8050393293301263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validate] MAE Loss Across Timepoints: [0.0597888  0.05555879]\n",
      "[Validate] TP Loss Across Timepoints: [8.76103414 3.12146428]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.49203468 0.71122593]\n",
      "Epoch [5/25]\n",
      "[Train] MAE Loss: 0.034523792254428066, TP Loss: 1.7756375884016355\n",
      "[Validate] MAE Loss Across Timepoints: [0.05853408 0.05392247]\n",
      "[Validate] TP Loss Across Timepoints: [8.49249471 2.90131226]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54321201 0.72200769]\n",
      "Epoch [6/25]\n",
      "[Train] MAE Loss: 0.034175263221065205, TP Loss: 1.7219595129291216\n",
      "[Validate] MAE Loss Across Timepoints: [0.05666762 0.05287096]\n",
      "[Validate] TP Loss Across Timepoints: [8.13605143 2.75041224]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.6295787 0.7810929]\n",
      "Epoch [7/25]\n",
      "[Train] MAE Loss: 0.03275969338913758, TP Loss: 1.6154164418578147\n",
      "[Validate] MAE Loss Across Timepoints: [0.05573877 0.05190353]\n",
      "[Validate] TP Loss Across Timepoints: [8.10311534 2.66389109]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48933167 0.68987116]\n",
      "Epoch [8/25]\n",
      "[Train] MAE Loss: 0.03223576151455442, TP Loss: 1.5821489050984383\n",
      "[Validate] MAE Loss Across Timepoints: [0.05493115 0.05076654]\n",
      "[Validate] TP Loss Across Timepoints: [7.95034078 2.51634547]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54065366 0.67668338]\n",
      "Epoch [9/25]\n",
      "[Train] MAE Loss: 0.031951140395055214, TP Loss: 1.5854482635855676\n",
      "[Validate] MAE Loss Across Timepoints: [0.05491305 0.0507409 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.90768687 2.46538264]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52461318 0.66122074]\n",
      "Epoch [10/25]\n",
      "[Train] MAE Loss: 0.03184492706010739, TP Loss: 1.5730689026415348\n",
      "[Validate] MAE Loss Across Timepoints: [0.05464163 0.0503129 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.82573751 2.38999786]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.55626864 0.72481748]\n",
      "Epoch [11/25]\n",
      "[Train] MAE Loss: 0.03166386193285386, TP Loss: 1.5069724664092063\n",
      "[Validate] MAE Loss Across Timepoints: [0.05427857 0.04974633]\n",
      "[Validate] TP Loss Across Timepoints: [7.69219513 2.2443545 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.47838134 0.69198179]\n",
      "Epoch [12/25]\n",
      "[Train] MAE Loss: 0.031474374638249474, TP Loss: 1.5093118282655875\n",
      "[Validate] MAE Loss Across Timepoints: [0.05314852 0.04890654]\n",
      "[Validate] TP Loss Across Timepoints: [7.67089945 2.29239044]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.5363974  0.70649039]\n",
      "Epoch [13/25]\n",
      "[Train] MAE Loss: 0.03019148080299298, TP Loss: 1.4211810387670993\n",
      "[Validate] MAE Loss Across Timepoints: [0.05211811 0.04744134]\n",
      "[Validate] TP Loss Across Timepoints: [7.52740021 2.12566592]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57545708 0.8113306 ]\n",
      "Epoch [14/25]\n",
      "[Train] MAE Loss: 0.030076299452533324, TP Loss: 1.4561546770234903\n",
      "[Validate] MAE Loss Across Timepoints: [0.05232453 0.04787213]\n",
      "[Validate] TP Loss Across Timepoints: [7.57869008 2.17651927]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61670799 0.76293402]\n",
      "Epoch [15/25]\n",
      "[Train] MAE Loss: 0.03007947330673536, TP Loss: 1.4495401037236055\n",
      "[Validate] MAE Loss Across Timepoints: [0.05231751 0.04764632]\n",
      "[Validate] TP Loss Across Timepoints: [7.65035655 2.20195821]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.69970678 0.80251102]\n",
      "Epoch [16/25]\n",
      "[Train] MAE Loss: 0.029910521457592647, TP Loss: 1.4374552095929782\n",
      "[Validate] MAE Loss Across Timepoints: [0.0521408  0.04760645]\n",
      "[Validate] TP Loss Across Timepoints: [7.55924733 2.11200943]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60919176 0.71847045]\n",
      "Epoch [17/25]\n",
      "[Train] MAE Loss: 0.02988617606461048, TP Loss: 1.43843038007617\n",
      "[Validate] MAE Loss Across Timepoints: [0.05218914 0.04754746]\n",
      "[Validate] TP Loss Across Timepoints: [7.63378957 2.16416855]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.68804245 0.74722857]\n",
      "Epoch [18/25]\n",
      "[Train] MAE Loss: 0.029697761281083028, TP Loss: 1.3953344057003656\n",
      "[Validate] MAE Loss Across Timepoints: [0.05202897 0.04756516]\n",
      "[Validate] TP Loss Across Timepoints: [7.52637634 2.09964841]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.5543956  0.77746538]\n",
      "Epoch [19/25]\n",
      "[Train] MAE Loss: 0.029736854818960032, TP Loss: 1.3885006075104078\n",
      "[Validate] MAE Loss Across Timepoints: [0.05181906 0.04715383]\n",
      "[Validate] TP Loss Across Timepoints: [7.45782369 2.03580437]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61690936 0.75006887]\n",
      "Epoch [20/25]\n",
      "[Train] MAE Loss: 0.029685127642005683, TP Loss: 1.413944346209367\n",
      "[Validate] MAE Loss Across Timepoints: [0.05183285 0.04707589]\n",
      "[Validate] TP Loss Across Timepoints: [7.4886439  2.03584302]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.68468228 0.84218037]\n",
      "Epoch [21/25]\n",
      "[Train] MAE Loss: 0.029766264495750268, TP Loss: 1.4071714875598749\n",
      "[Validate] MAE Loss Across Timepoints: [0.05197496 0.0475595 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.54117533 2.08691572]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57987665 0.78105343]\n",
      "Epoch [22/25]\n",
      "[Train] MAE Loss: 0.029685467729965845, TP Loss: 1.392733564476172\n",
      "[Validate] MAE Loss Across Timepoints: [0.05180082 0.04715605]\n",
      "[Validate] TP Loss Across Timepoints: [7.50394135 2.03936704]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60031285 0.79054753]\n",
      "Epoch [23/25]\n",
      "[Train] MAE Loss: 0.029562518000602722, TP Loss: 1.3721245656410852\n",
      "[Validate] MAE Loss Across Timepoints: [0.05188642 0.04718339]\n",
      "[Validate] TP Loss Across Timepoints: [7.53571676 2.03197683]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63209811 0.75421369]\n",
      "Epoch [24/25]\n",
      "[Train] MAE Loss: 0.029629339867581924, TP Loss: 1.3808935267229876\n",
      "[Validate] MAE Loss Across Timepoints: [0.05205374 0.04741564]\n",
      "[Validate] TP Loss Across Timepoints: [7.60095622 2.09320323]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56314345 0.84075979]\n",
      "Epoch [25/25]\n",
      "[Train] MAE Loss: 0.029683403391391038, TP Loss: 1.4238234082857768\n",
      "[Validate] MAE Loss Across Timepoints: [0.05191645 0.04721513]\n",
      "[Validate] TP Loss Across Timepoints: [7.56387278 2.04761759]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.5883722  0.81099587]\n",
      "\n",
      "epochs finished with time:241.18758821487427\n",
      "\n",
      "Current memory usage: 2629.62 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04678823 0.05074179]\n",
      "[Test] TP Loss Across Timepoints: [2.55695925 4.23003789]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.53451021 0.53229307]\n",
      "------------------------------------Fold [3/3]-----------------------------------------\n",
      "Epoch [1/25]\n",
      "[Train] MAE Loss: 0.04895279010136922, TP Loss: 2.70649723559618\n",
      "[Validate] MAE Loss Across Timepoints: [0.0614392  0.06372759]\n",
      "[Validate] TP Loss Across Timepoints: [3.09603524 2.92451096]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.5463231  0.83723346]\n",
      "Epoch [2/25]\n",
      "[Train] MAE Loss: 0.04060254953801632, TP Loss: 2.222775821387768\n",
      "[Validate] MAE Loss Across Timepoints: [0.05234544 0.05726525]\n",
      "[Validate] TP Loss Across Timepoints: [2.39797282 2.48470497]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.74084551 0.56126069]\n",
      "Epoch [3/25]\n",
      "[Train] MAE Loss: 0.03670158023014665, TP Loss: 1.9872696767250697\n",
      "[Validate] MAE Loss Across Timepoints: [0.04774509 0.05250046]\n",
      "[Validate] TP Loss Across Timepoints: [2.0631907  2.27042747]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53133153 0.62469411]\n",
      "Epoch [4/25]\n",
      "[Train] MAE Loss: 0.03393336730077863, TP Loss: 1.8442337065935135\n",
      "[Validate] MAE Loss Across Timepoints: [0.04403538 0.04789168]\n",
      "[Validate] TP Loss Across Timepoints: [1.80359864 1.96239614]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.68642368 0.72477136]\n",
      "Epoch [5/25]\n",
      "[Train] MAE Loss: 0.032627058370659746, TP Loss: 1.7380501374602317\n",
      "[Validate] MAE Loss Across Timepoints: [0.04298003 0.04653239]\n",
      "[Validate] TP Loss Across Timepoints: [1.68337929 1.82832384]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56404134 0.67206209]\n",
      "Epoch [6/25]\n",
      "[Train] MAE Loss: 0.03181968340650201, TP Loss: 1.7024397338430086\n",
      "[Validate] MAE Loss Across Timepoints: [0.04187494 0.04504902]\n",
      "[Validate] TP Loss Across Timepoints: [1.61521626 1.71460283]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.03457271 0.75573059]\n",
      "Epoch [7/25]\n",
      "[Train] MAE Loss: 0.031005517610659204, TP Loss: 1.6460254157582919\n",
      "[Validate] MAE Loss Across Timepoints: [0.04176653 0.04483328]\n",
      "[Validate] TP Loss Across Timepoints: [1.62848258 1.72196126]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.90446413 0.92155153]\n",
      "Epoch [8/25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.030808371119201185, TP Loss: 1.6311018099387486\n",
      "[Validate] MAE Loss Across Timepoints: [0.04156931 0.04446583]\n",
      "[Validate] TP Loss Across Timepoints: [1.60966551 1.68739915]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.97298003 0.8486171 ]\n",
      "Epoch [9/25]\n",
      "[Train] MAE Loss: 0.030578241466234127, TP Loss: 1.6678011655807494\n",
      "[Validate] MAE Loss Across Timepoints: [0.04164179 0.04457339]\n",
      "[Validate] TP Loss Across Timepoints: [1.62054157 1.70539796]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.93106833 0.8805858 ]\n",
      "Epoch [10/25]\n",
      "[Train] MAE Loss: 0.03058295880133907, TP Loss: 1.6487637432912985\n",
      "[Validate] MAE Loss Across Timepoints: [0.041328   0.04415325]\n",
      "[Validate] TP Loss Across Timepoints: [1.55399346 1.61633801]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.91376273 0.81144308]\n",
      "Epoch [11/25]\n",
      "[Train] MAE Loss: 0.030360520537942647, TP Loss: 1.6352877487738928\n",
      "[Validate] MAE Loss Across Timepoints: [0.04135643 0.04419596]\n",
      "[Validate] TP Loss Across Timepoints: [1.59899354 1.68378246]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.9898288 0.8125394]\n",
      "Epoch [12/25]\n",
      "[Train] MAE Loss: 0.03034016185750564, TP Loss: 1.6728965292374294\n",
      "[Validate] MAE Loss Across Timepoints: [0.04137984 0.04413942]\n",
      "[Validate] TP Loss Across Timepoints: [1.604756   1.68155229]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.93445657 0.79948448]\n",
      "Epoch [13/25]\n",
      "[Train] MAE Loss: 0.03002911914760868, TP Loss: 1.57976222311457\n",
      "[Validate] MAE Loss Across Timepoints: [0.04104993 0.04382794]\n",
      "[Validate] TP Loss Across Timepoints: [1.56787908 1.63546526]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.92837841 0.81338694]\n",
      "Epoch [14/25]\n",
      "[Train] MAE Loss: 0.0301194096604983, TP Loss: 1.6238049191733201\n",
      "[Validate] MAE Loss Across Timepoints: [0.04103449 0.04381017]\n",
      "[Validate] TP Loss Across Timepoints: [1.56341541 1.62891793]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02460439 0.74676284]\n",
      "Epoch [15/25]\n",
      "[Train] MAE Loss: 0.030016377537200847, TP Loss: 1.6080918480952582\n",
      "[Validate] MAE Loss Across Timepoints: [0.04098237 0.04380347]\n",
      "[Validate] TP Loss Across Timepoints: [1.54585302 1.62192452]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02676774 0.80047782]\n",
      "Epoch [16/25]\n",
      "[Train] MAE Loss: 0.02980208502461513, TP Loss: 1.6180682931095363\n",
      "[Validate] MAE Loss Across Timepoints: [0.04102572 0.04386733]\n",
      "[Validate] TP Loss Across Timepoints: [1.57028472 1.66102195]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.93933064 0.77835481]\n",
      "Epoch [17/25]\n",
      "[Train] MAE Loss: 0.029893655019501846, TP Loss: 1.6047853584090868\n",
      "[Validate] MAE Loss Across Timepoints: [0.04077356 0.0436052 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.49472821 1.55921996]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.8967687  0.77369604]\n",
      "Epoch [18/25]\n",
      "[Train] MAE Loss: 0.029795614474763473, TP Loss: 1.6053150549530983\n",
      "[Validate] MAE Loss Across Timepoints: [0.04080477 0.04362081]\n",
      "[Validate] TP Loss Across Timepoints: [1.49132085 1.56715012]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.91045845 0.76762569]\n",
      "Epoch [19/25]\n",
      "[Train] MAE Loss: 0.02968884160121282, TP Loss: 1.5767641050120196\n",
      "[Validate] MAE Loss Across Timepoints: [0.04088356 0.04386816]\n",
      "[Validate] TP Loss Across Timepoints: [1.55256617 1.66393399]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.00430974 0.87553032]\n",
      "Epoch [20/25]\n",
      "[Train] MAE Loss: 0.029645347160597642, TP Loss: 1.5989941669007142\n",
      "[Validate] MAE Loss Across Timepoints: [0.04073254 0.04358565]\n",
      "[Validate] TP Loss Across Timepoints: [1.50671899 1.59185469]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.88578053 0.7675966 ]\n",
      "Epoch [21/25]\n",
      "[Train] MAE Loss: 0.029689074462900557, TP Loss: 1.5749058954417705\n",
      "[Validate] MAE Loss Across Timepoints: [0.0406948  0.04355641]\n",
      "[Validate] TP Loss Across Timepoints: [1.50174356 1.59141326]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.85388544 0.78940549]\n",
      "Epoch [22/25]\n",
      "[Train] MAE Loss: 0.02961690751835704, TP Loss: 1.6015292823314666\n",
      "[Validate] MAE Loss Across Timepoints: [0.04053695 0.04342697]\n",
      "[Validate] TP Loss Across Timepoints: [1.48042166 1.55537653]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.8785062  0.80591073]\n",
      "Epoch [23/25]\n",
      "[Train] MAE Loss: 0.029548020816097656, TP Loss: 1.5702470694979032\n",
      "[Validate] MAE Loss Across Timepoints: [0.0406627  0.04356431]\n",
      "[Validate] TP Loss Across Timepoints: [1.50683784 1.60569668]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.90059339 0.79978814]\n",
      "Epoch [24/25]\n",
      "[Train] MAE Loss: 0.029643219461043677, TP Loss: 1.581252496689558\n",
      "[Validate] MAE Loss Across Timepoints: [0.04080209 0.04380434]\n",
      "[Validate] TP Loss Across Timepoints: [1.540043   1.64949167]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.92596354 0.8485943 ]\n",
      "Epoch [25/25]\n",
      "[Train] MAE Loss: 0.02942327195778489, TP Loss: 1.5589835971593857\n",
      "[Validate] MAE Loss Across Timepoints: [0.04070549 0.0436752 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.51476812 1.62589717]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94822705 0.80167244]\n",
      "\n",
      "epochs finished with time:248.14660239219666\n",
      "\n",
      "Current memory usage: 2628.34 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04188107 0.04486306]\n",
      "[Test] TP Loss Across Timepoints: [3.58251046 3.32282731]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.77478187 0.86181415]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_oasis_language.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    # Create model instance\n",
    "    model = GConvGRUModel(device=device, input_weights=input_weights, input_scaling=1e-1).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1): \n",
    "                pred = model(data[t])\n",
    "                real = data[t + 1]\n",
    "        \n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss\n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap,\n",
    "                                                                                            X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
