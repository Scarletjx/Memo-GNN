{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24289,
     "status": "ok",
     "timestamp": 1694168463049,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "7q88jl49dAZx",
    "outputId": "87b07f64-7289-4e79-b63b-cc5759d44b85"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import argparse\n",
    "import timeit\n",
    "from dataset import prepare_data\n",
    "import psutil\n",
    "import torch\n",
    "from models.gconvGRU_simple import GConvGRUModel\n",
    "from memory_capacity_utils import gen_lag_data_embeddings, compute_memory_capacity_vectorized, get_mem_cap_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuyWYNaidZie"
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Args for graph predition')\n",
    "    parser.add_argument('-num_folds', type=int, default=3, help='cv number')\n",
    "    parser.add_argument('--num_timepoints', type=int, default=3,\n",
    "                        help='Number of timepoints')\n",
    "    parser.add_argument('-num_epochs', type=int, default=25, help='number of epochs')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, help=\"Learning rate\")\n",
    "    parser.add_argument('--memcap_coef', type=float, default=0.00008, help=\"Memory Capacity Loss Coefficient\")\n",
    "    parser.add_argument('-max_lag', type=int, default=35, help='Lag tao for memory capacity signals')\n",
    "    parser.add_argument('-save_path',type=str,default = '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/',help='Path to the saved results')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1579,
     "status": "ok",
     "timestamp": 1694168465038,
     "user": {
      "displayName": "Павел Бозмаров",
      "userId": "13372247782600851572"
     },
     "user_tz": -60
    },
    "id": "CJfqLrF4bbv1"
   },
   "outputs": [],
   "source": [
    "dataset = np.load('datasets/oasis_data.npy')\n",
    "dataset = torch.from_numpy(dataset).squeeze()\n",
    "dataset = dataset.type(torch.FloatTensor)\n",
    "dataset = np.delete(dataset,88,axis=0)\n",
    "\n",
    "# dataset = np.load(\"datasets/multivariate_simulation_data_2.npy\")\n",
    "# dataset = torch.from_numpy(dataset).squeeze()\n",
    "# dataset = dataset.type(torch.FloatTensor)\n",
    "# dataset = dataset[:, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([113, 3, 35, 35])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq-tRUzrK_Zw"
   },
   "source": [
    "# Set up the network architecture and train-validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljZ0c4g_uu9g"
   },
   "source": [
    "**Train-validate-functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/real_and_predicted_graphs' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/train_losses/mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/train_losses/reservoir_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/train_losses/bio_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/train_losses/tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/train_losses/total_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/test_mae_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/test_tp_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/test_memcap_losses' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/test_predicted' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/test_original' already exists.\n",
      "Directory '/vol/bitbucket/sx420/4D-FedGNN-Plus/results/reservoir_gconvGRU_language_1/trained_models' already exists.\n"
     ]
    }
   ],
   "source": [
    "def create_directory_if_not_exists(directory):\n",
    "    \"\"\"\n",
    "    Checks if a specified directory exists, and creates it if it doesn't.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): Path of the directory to check and potentially create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(f\"Directory '{directory}' was created.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory}' already exists.\")\n",
    "\n",
    "# Create the results folders\n",
    "create_directory_if_not_exists(args.save_path+'real_and_predicted_graphs')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/reservoir_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/bio_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'train_losses/total_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_mae_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_tp_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_memcap_losses')\n",
    "create_directory_if_not_exists(args.save_path+'test_predicted')\n",
    "create_directory_if_not_exists(args.save_path+'test_original')\n",
    "create_directory_if_not_exists(args.save_path+'trained_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed = 777\n",
    "np.random.seed(manual_seed)\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "\n",
    "embeddings = np.load('datasets/gutenberg_embeddings.npy')\n",
    "# Reservoir signals\n",
    "X_train_res_np, y_train_res_np = gen_lag_data_embeddings(embeddings, 1000, args.max_lag, 41)\n",
    "X_test_res_np, y_test_res_np = gen_lag_data_embeddings(embeddings, 500, args.max_lag, 42)\n",
    "X_train_res = torch.from_numpy(X_train_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "X_test_res = torch.from_numpy(X_test_res_np).unsqueeze(1).to(device, dtype=torch.float64)\n",
    "y_train_res = torch.from_numpy(y_train_res_np).to(device, dtype=torch.float64)\n",
    "y_test_res = torch.from_numpy(y_test_res_np).to(device, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, validation_subjects, mem_cap_data, X_train, y_train, X_test, y_test):\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "    \n",
    "    val_mae_loss = np.zeros(args.num_timepoints - 1)\n",
    "    val_tp_loss = np.zeros(args.num_timepoints - 1)\n",
    "    mem_cap = np.zeros(args.num_timepoints - 1)\n",
    "    predicted = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    actual = np.zeros((validation_subjects.shape[0], args.num_timepoints - 1, 35, 35))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for n_subject, data in enumerate(validation_subjects):\n",
    "            input = data[0]\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred = model(input)\n",
    "                val_mae_loss[t] += mael(pred, data[t + 1])\n",
    "                val_tp_loss[t] += tp(pred.sum(dim=-1), data[t + 1].sum(dim=-1))\n",
    "                input = pred\n",
    "                \n",
    "                pred_mem_cap = get_mem_cap_from_model(model, pred, \n",
    "                                                      X_train, y_train, X_test, y_test)\n",
    "                actual_mem_cap = torch.tensor(mem_cap_data[n_subject, t + 1]).to(device)\n",
    "                mem_cap[t] += torch.abs(pred_mem_cap - actual_mem_cap)\n",
    "\n",
    "                predicted[n_subject, t] = pred.cpu().detach().numpy()\n",
    "                actual[n_subject, t] = data[t + 1].cpu().detach().numpy()\n",
    "                \n",
    "\n",
    "    avg_val_mae_loss = val_mae_loss/len(validation_subjects)\n",
    "    avg_val_tp_loss = val_tp_loss/len(validation_subjects)\n",
    "    avg_val_mae_mem_cap = mem_cap/len(validation_subjects)\n",
    "\n",
    "    return avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, predicted, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Fold [1/3]-----------------------------------------\n",
      "Epoch [1/25]\n",
      "[Train] MAE Loss: 0.050970486178994176, TP Loss: 3.4072265520691873, MAE of Mem Caps Loss: 0.475922421454871\n",
      "[Validate] MAE Loss Across Timepoints: [0.07704723 0.06452254]\n",
      "[Validate] TP Loss Across Timepoints: [11.21889445  2.24554977]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.58347092 0.71696937]\n",
      "Epoch [2/25]\n",
      "[Train] MAE Loss: 0.043450038973242046, TP Loss: 2.785139349848032, MAE of Mem Caps Loss: 0.5500000502693383\n",
      "[Validate] MAE Loss Across Timepoints: [0.06563813 0.05378991]\n",
      "[Validate] TP Loss Across Timepoints: [9.41786397 1.61668803]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.49580023 0.56260843]\n",
      "Epoch [3/25]\n",
      "[Train] MAE Loss: 0.03881583400070667, TP Loss: 2.3804535220066705, MAE of Mem Caps Loss: 0.610896811862009\n",
      "[Validate] MAE Loss Across Timepoints: [0.06297301 0.05110054]\n",
      "[Validate] TP Loss Across Timepoints: [9.10221456 1.53785884]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52203854 0.59977935]\n",
      "Epoch [4/25]\n",
      "[Train] MAE Loss: 0.03623939749474327, TP Loss: 2.2166797732313475, MAE of Mem Caps Loss: 0.6400499112114179\n",
      "[Validate] MAE Loss Across Timepoints: [0.05765694 0.04477056]\n",
      "[Validate] TP Loss Across Timepoints: [8.19178009 1.22885335]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.46253141 0.56655064]\n",
      "Epoch [5/25]\n",
      "[Train] MAE Loss: 0.03437630419308941, TP Loss: 2.055309892445803, MAE of Mem Caps Loss: 0.6272912159943\n",
      "[Validate] MAE Loss Across Timepoints: [0.05728275 0.04372082]\n",
      "[Validate] TP Loss Across Timepoints: [8.24417979 1.25594177]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48069604 0.58871048]\n",
      "Epoch [6/25]\n",
      "[Train] MAE Loss: 0.03383053432529171, TP Loss: 2.069221192598343, MAE of Mem Caps Loss: 0.5364073228296086\n",
      "[Validate] MAE Loss Across Timepoints: [0.05682018 0.04289219]\n",
      "[Validate] TP Loss Across Timepoints: [8.10807037 1.17995351]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.45357343 0.59235658]\n",
      "Epoch [7/25]\n",
      "[Train] MAE Loss: 0.03363978834822774, TP Loss: 2.0683576717972754, MAE of Mem Caps Loss: 0.605034361865979\n",
      "[Validate] MAE Loss Across Timepoints: [0.05653663 0.0424376 ]\n",
      "[Validate] TP Loss Across Timepoints: [8.09648031 1.1706262 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.49934658 0.54267586]\n",
      "Epoch [8/25]\n",
      "[Train] MAE Loss: 0.03326575653627515, TP Loss: 2.007207975536585, MAE of Mem Caps Loss: 0.6126564200820696\n",
      "[Validate] MAE Loss Across Timepoints: [0.056389   0.04237707]\n",
      "[Validate] TP Loss Across Timepoints: [8.04458364 1.14973437]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56479396 0.57513222]\n",
      "Epoch [9/25]\n",
      "[Train] MAE Loss: 0.033256896181652944, TP Loss: 2.071675759802262, MAE of Mem Caps Loss: 0.5440878242974558\n",
      "[Validate] MAE Loss Across Timepoints: [0.05639829 0.04221187]\n",
      "[Validate] TP Loss Across Timepoints: [8.10601196 1.15342267]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.40935565 0.51410353]\n",
      "Epoch [10/25]\n",
      "[Train] MAE Loss: 0.03296323555211226, TP Loss: 2.038168763866027, MAE of Mem Caps Loss: 0.5540285979375\n",
      "[Validate] MAE Loss Across Timepoints: [0.05609083 0.04195276]\n",
      "[Validate] TP Loss Across Timepoints: [7.97910563 1.09538167]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54183101 0.53640258]\n",
      "Epoch [11/25]\n",
      "[Train] MAE Loss: 0.032962781252960364, TP Loss: 2.0023195154964926, MAE of Mem Caps Loss: 0.565051762714175\n",
      "[Validate] MAE Loss Across Timepoints: [0.05588837 0.04181845]\n",
      "[Validate] TP Loss Across Timepoints: [7.97819621 1.10212339]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.62646394 0.55058032]\n",
      "Epoch [12/25]\n",
      "[Train] MAE Loss: 0.03284820324430863, TP Loss: 2.0210951782763003, MAE of Mem Caps Loss: 0.5179698308955439\n",
      "[Validate] MAE Loss Across Timepoints: [0.05586406 0.0417822 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.98517812 1.09752019]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63382681 0.58031477]\n",
      "Epoch [13/25]\n",
      "[Train] MAE Loss: 0.03260263989989956, TP Loss: 2.0276930809020994, MAE of Mem Caps Loss: 0.6081225513269962\n",
      "[Validate] MAE Loss Across Timepoints: [0.05602176 0.04184232]\n",
      "[Validate] TP Loss Across Timepoints: [8.06298625 1.12036578]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56751745 0.59150463]\n",
      "Epoch [14/25]\n",
      "[Train] MAE Loss: 0.03254980199659864, TP Loss: 1.9556535710891088, MAE of Mem Caps Loss: 0.5492658604117497\n",
      "[Validate] MAE Loss Across Timepoints: [0.05598795 0.04194772]\n",
      "[Validate] TP Loss Across Timepoints: [7.91933339 1.05955887]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.5569776  0.56355614]\n",
      "Epoch [15/25]\n",
      "[Train] MAE Loss: 0.03203170951455832, TP Loss: 1.9610520169138907, MAE of Mem Caps Loss: 0.4944688529360004\n",
      "[Validate] MAE Loss Across Timepoints: [0.054423   0.04049505]\n",
      "[Validate] TP Loss Across Timepoints: [7.78344472 0.98740686]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53044351 0.52605794]\n",
      "Epoch [16/25]\n",
      "[Train] MAE Loss: 0.03189151988675197, TP Loss: 1.9714920250078043, MAE of Mem Caps Loss: 0.4523048382810401\n",
      "[Validate] MAE Loss Across Timepoints: [0.05445894 0.04062322]\n",
      "[Validate] TP Loss Across Timepoints: [7.8022817  0.98841909]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.46128862 0.52559073]\n",
      "Epoch [17/25]\n",
      "[Train] MAE Loss: 0.031764691788703205, TP Loss: 1.957581839710474, MAE of Mem Caps Loss: 0.4554312125036696\n",
      "[Validate] MAE Loss Across Timepoints: [0.05449284 0.0407623 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.83252207 0.99155184]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.43060123 0.55758009]\n",
      "Epoch [18/25]\n",
      "[Train] MAE Loss: 0.03167093653852741, TP Loss: 1.9208246350288392, MAE of Mem Caps Loss: 0.4735814580864836\n",
      "[Validate] MAE Loss Across Timepoints: [0.05448624 0.04053796]\n",
      "[Validate] TP Loss Across Timepoints: [7.83081207 0.99569295]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.90473878 0.96595219]\n",
      "Epoch [19/25]\n",
      "[Train] MAE Loss: 0.03173557858293255, TP Loss: 1.966126630206903, MAE of Mem Caps Loss: 0.4228855987597495\n",
      "[Validate] MAE Loss Across Timepoints: [0.05459044 0.04079539]\n",
      "[Validate] TP Loss Across Timepoints: [7.8477656 1.0047671]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57400623 0.59075006]\n",
      "Epoch [20/25]\n",
      "[Train] MAE Loss: 0.03154024804631869, TP Loss: 1.9339665231605372, MAE of Mem Caps Loss: 0.4954500402256429\n",
      "[Validate] MAE Loss Across Timepoints: [0.05447843 0.04041464]\n",
      "[Validate] TP Loss Across Timepoints: [7.87398478 1.02005628]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56931114 0.54459462]\n",
      "Epoch [21/25]\n",
      "[Train] MAE Loss: 0.0316759471471111, TP Loss: 1.9290360026061535, MAE of Mem Caps Loss: 0.5218276320879739\n",
      "[Validate] MAE Loss Across Timepoints: [0.0547387  0.04079182]\n",
      "[Validate] TP Loss Across Timepoints: [7.93638407 1.03069719]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48630493 0.6080768 ]\n",
      "Epoch [22/25]\n",
      "[Train] MAE Loss: 0.031635094837596016, TP Loss: 1.9455161832273007, MAE of Mem Caps Loss: 0.4622988729583902\n",
      "[Validate] MAE Loss Across Timepoints: [0.05442917 0.0405765 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.81938985 0.99061883]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.5130374  0.57743655]\n",
      "Epoch [23/25]\n",
      "[Train] MAE Loss: 0.03149011554196477, TP Loss: 1.947691794981559, MAE of Mem Caps Loss: 0.47276321406817473\n",
      "[Validate] MAE Loss Across Timepoints: [0.05439212 0.0407257 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.81611938 0.98406474]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54618644 0.56682978]\n",
      "Epoch [24/25]\n",
      "[Train] MAE Loss: 0.0314407853409648, TP Loss: 1.9230015518764654, MAE of Mem Caps Loss: 0.4889113955614442\n",
      "[Validate] MAE Loss Across Timepoints: [0.05426453 0.04041744]\n",
      "[Validate] TP Loss Across Timepoints: [7.8176534  0.98319473]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54097032 0.57507091]\n",
      "Epoch [25/25]\n",
      "[Train] MAE Loss: 0.0314575952788194, TP Loss: 1.918917749573787, MAE of Mem Caps Loss: 0.5112003691304471\n",
      "[Validate] MAE Loss Across Timepoints: [0.0542052  0.04049441]\n",
      "[Validate] TP Loss Across Timepoints: [7.7769928  0.96607056]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57587823 0.59696583]\n",
      "\n",
      "epochs finished with time:1128.2979545593262\n",
      "\n",
      "Current memory usage: 2610.37 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.03902055 0.04358772]\n",
      "[Test] TP Loss Across Timepoints: [1.14313929 1.68006917]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.53399216 0.52756535]\n",
      "------------------------------------Fold [2/3]-----------------------------------------\n",
      "Epoch [1/25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.0479508688673377, TP Loss: 3.0098415305217108, MAE of Mem Caps Loss: 0.3854556166147825\n",
      "[Validate] MAE Loss Across Timepoints: [0.07403733 0.06924137]\n",
      "[Validate] TP Loss Across Timepoints: [11.3413564   4.38718211]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.70529371 1.35317451]\n",
      "Epoch [2/25]\n",
      "[Train] MAE Loss: 0.04119245344772935, TP Loss: 2.415866892536481, MAE of Mem Caps Loss: 0.4083580028085392\n",
      "[Validate] MAE Loss Across Timepoints: [0.06519248 0.06154884]\n",
      "[Validate] TP Loss Across Timepoints: [9.77233073 3.60208817]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60151208 0.80976541]\n",
      "Epoch [3/25]\n",
      "[Train] MAE Loss: 0.03719441092883547, TP Loss: 1.9498479614655178, MAE of Mem Caps Loss: 0.3766323295947549\n",
      "[Validate] MAE Loss Across Timepoints: [0.06085068 0.05643325]\n",
      "[Validate] TP Loss Across Timepoints: [8.97796326 3.14715296]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56293261 0.71436125]\n",
      "Epoch [4/25]\n",
      "[Train] MAE Loss: 0.03511514089380701, TP Loss: 1.810601922372977, MAE of Mem Caps Loss: 0.3253510689765522\n",
      "[Validate] MAE Loss Across Timepoints: [0.05990002 0.05556219]\n",
      "[Validate] TP Loss Across Timepoints: [8.79996847 3.1325119 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.51514787 0.72135313]\n",
      "Epoch [5/25]\n",
      "[Train] MAE Loss: 0.034535466134548186, TP Loss: 1.781093634168307, MAE of Mem Caps Loss: 0.32486275268841686\n",
      "[Validate] MAE Loss Across Timepoints: [0.05860126 0.05397592]\n",
      "[Validate] TP Loss Across Timepoints: [8.51961568 2.92071838]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56061311 0.73963393]\n",
      "Epoch [6/25]\n",
      "[Train] MAE Loss: 0.034262069904555874, TP Loss: 1.7333395245174568, MAE of Mem Caps Loss: 0.32186444581284596\n",
      "[Validate] MAE Loss Across Timepoints: [0.05711006 0.05303719]\n",
      "[Validate] TP Loss Across Timepoints: [8.21348521 2.78166758]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56767394 0.73198785]\n",
      "Epoch [7/25]\n",
      "[Train] MAE Loss: 0.03304996533940236, TP Loss: 1.6530024372041225, MAE of Mem Caps Loss: 0.3617095475547284\n",
      "[Validate] MAE Loss Across Timepoints: [0.05599642 0.05220071]\n",
      "[Validate] TP Loss Across Timepoints: [8.11597493 2.67150625]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48642648 0.70638549]\n",
      "Epoch [8/25]\n",
      "[Train] MAE Loss: 0.03227527448907495, TP Loss: 1.5875388190150261, MAE of Mem Caps Loss: 0.36173277036712914\n",
      "[Validate] MAE Loss Across Timepoints: [0.05504419 0.05086685]\n",
      "[Validate] TP Loss Across Timepoints: [7.98278605 2.53855591]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.54196959 0.68357571]\n",
      "Epoch [9/25]\n",
      "[Train] MAE Loss: 0.03195103670780857, TP Loss: 1.5877364359796047, MAE of Mem Caps Loss: 0.3383643751925722\n",
      "[Validate] MAE Loss Across Timepoints: [0.05497738 0.05074661]\n",
      "[Validate] TP Loss Across Timepoints: [7.93536275 2.47749557]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48515636 0.69235028]\n",
      "Epoch [10/25]\n",
      "[Train] MAE Loss: 0.031856513240685065, TP Loss: 1.5814372092485427, MAE of Mem Caps Loss: 0.33738493000489284\n",
      "[Validate] MAE Loss Across Timepoints: [0.05463114 0.05022651]\n",
      "[Validate] TP Loss Across Timepoints: [7.8281601  2.38423106]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53182593 0.69416355]\n",
      "Epoch [11/25]\n",
      "[Train] MAE Loss: 0.031675771623849866, TP Loss: 1.5144693776965141, MAE of Mem Caps Loss: 0.3444099886470473\n",
      "[Validate] MAE Loss Across Timepoints: [0.05429374 0.04976023]\n",
      "[Validate] TP Loss Across Timepoints: [7.69207204 2.25130514]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53277309 0.72225975]\n",
      "Epoch [12/25]\n",
      "[Train] MAE Loss: 0.03147261614600817, TP Loss: 1.5123168935378393, MAE of Mem Caps Loss: 0.3228386469546188\n",
      "[Validate] MAE Loss Across Timepoints: [0.05319127 0.04892805]\n",
      "[Validate] TP Loss Across Timepoints: [7.68446554 2.30556488]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52374867 0.70032818]\n",
      "Epoch [13/25]\n",
      "[Train] MAE Loss: 0.030197970662266017, TP Loss: 1.4425958774983882, MAE of Mem Caps Loss: 0.508096566972798\n",
      "[Validate] MAE Loss Across Timepoints: [0.05226411 0.04756995]\n",
      "[Validate] TP Loss Across Timepoints: [7.58002218 2.16898473]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52650489 0.8140479 ]\n",
      "Epoch [14/25]\n",
      "[Train] MAE Loss: 0.03008563400556644, TP Loss: 1.4763291309277216, MAE of Mem Caps Loss: 0.5060040919377023\n",
      "[Validate] MAE Loss Across Timepoints: [0.05250867 0.04800571]\n",
      "[Validate] TP Loss Across Timepoints: [7.65761515 2.23251444]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.60012229 0.76314994]\n",
      "Epoch [15/25]\n",
      "[Train] MAE Loss: 0.030104340706020593, TP Loss: 1.4769545080761115, MAE of Mem Caps Loss: 0.5077715857821757\n",
      "[Validate] MAE Loss Across Timepoints: [0.05253294 0.0478469 ]\n",
      "[Validate] TP Loss Across Timepoints: [7.72850138 2.26306712]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.63696737 0.77046418]\n",
      "Epoch [16/25]\n",
      "[Train] MAE Loss: 0.02993095765511195, TP Loss: 1.467065560693542, MAE of Mem Caps Loss: 0.5084082770774888\n",
      "[Validate] MAE Loss Across Timepoints: [0.05233754 0.04777756]\n",
      "[Validate] TP Loss Across Timepoints: [7.63471018 2.17258453]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.55433712 0.73012179]\n",
      "Epoch [17/25]\n",
      "[Train] MAE Loss: 0.02991007429858049, TP Loss: 1.4672665591041247, MAE of Mem Caps Loss: 0.5166785344639858\n",
      "[Validate] MAE Loss Across Timepoints: [0.05235742 0.04768824]\n",
      "[Validate] TP Loss Across Timepoints: [7.69949188 2.21972911]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.64836491 0.74256601]\n",
      "Epoch [18/25]\n",
      "[Train] MAE Loss: 0.029723692188660302, TP Loss: 1.419441147396962, MAE of Mem Caps Loss: 0.489881933567159\n",
      "[Validate] MAE Loss Across Timepoints: [0.05219729 0.04765739]\n",
      "[Validate] TP Loss Across Timepoints: [7.58164419 2.13918279]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.53536852 0.78150957]\n",
      "Epoch [19/25]\n",
      "[Train] MAE Loss: 0.029780168800304332, TP Loss: 1.418537051975727, MAE of Mem Caps Loss: 0.46896057207955194\n",
      "[Validate] MAE Loss Across Timepoints: [0.0519682  0.04723351]\n",
      "[Validate] TP Loss Across Timepoints: [7.51527557 2.0801206 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.58760737 0.72340437]\n",
      "Epoch [20/25]\n",
      "[Train] MAE Loss: 0.02970530269667506, TP Loss: 1.436478508512179, MAE of Mem Caps Loss: 0.5014882221637055\n",
      "[Validate] MAE Loss Across Timepoints: [0.0519734  0.04717504]\n",
      "[Validate] TP Loss Across Timepoints: [7.53233795 2.07276688]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.61096159 0.75844956]\n",
      "Epoch [21/25]\n",
      "[Train] MAE Loss: 0.029799262620508672, TP Loss: 1.4345346063375473, MAE of Mem Caps Loss: 0.47662717027512735\n",
      "[Validate] MAE Loss Across Timepoints: [0.05210381 0.047597  ]\n",
      "[Validate] TP Loss Across Timepoints: [7.57861125 2.11540985]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.57651365 0.79948286]\n",
      "Epoch [22/25]\n",
      "[Train] MAE Loss: 0.029694001407672962, TP Loss: 1.4092399049550295, MAE of Mem Caps Loss: 0.4940146367133321\n",
      "[Validate] MAE Loss Across Timepoints: [0.05197106 0.04729574]\n",
      "[Validate] TP Loss Across Timepoints: [7.57206726 2.09540698]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.52512194 0.81257082]\n",
      "Epoch [23/25]\n",
      "[Train] MAE Loss: 0.02959135516236226, TP Loss: 1.3930686846375466, MAE of Mem Caps Loss: 0.4746344230001542\n",
      "[Validate] MAE Loss Across Timepoints: [0.0519713  0.04722403]\n",
      "[Validate] TP Loss Across Timepoints: [7.56807861 2.06662788]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.55779302 0.76036625]\n",
      "Epoch [24/25]\n",
      "[Train] MAE Loss: 0.029665696372588476, TP Loss: 1.406511448075374, MAE of Mem Caps Loss: 0.46639183531701706\n",
      "[Validate] MAE Loss Across Timepoints: [0.0522284  0.04751514]\n",
      "[Validate] TP Loss Across Timepoints: [7.64796346 2.13213005]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.59879904 0.80303961]\n",
      "Epoch [25/25]\n",
      "[Train] MAE Loss: 0.029703689956416687, TP Loss: 1.4407861476143202, MAE of Mem Caps Loss: 0.484333337093031\n",
      "[Validate] MAE Loss Across Timepoints: [0.05209924 0.04731199]\n",
      "[Validate] TP Loss Across Timepoints: [7.62871094 2.10034053]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56334302 0.79625636]\n",
      "\n",
      "epochs finished with time:1114.4217147827148\n",
      "\n",
      "Current memory usage: 2624.24 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04691429 0.05088002]\n",
      "[Test] TP Loss Across Timepoints: [2.60569562 4.29454803]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.49247591 0.52607735]\n",
      "------------------------------------Fold [3/3]-----------------------------------------\n",
      "Epoch [1/25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] MAE Loss: 0.04895974534253279, TP Loss: 2.7114733144640923, MAE of Mem Caps Loss: 0.4188534730684664\n",
      "[Validate] MAE Loss Across Timepoints: [0.06151683 0.06379341]\n",
      "[Validate] TP Loss Across Timepoints: [3.12761283 2.94754553]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.56987888 0.88854321]\n",
      "Epoch [2/25]\n",
      "[Train] MAE Loss: 0.0406184570863843, TP Loss: 2.238558176656564, MAE of Mem Caps Loss: 0.5353856219023072\n",
      "[Validate] MAE Loss Across Timepoints: [0.05250945 0.05743516]\n",
      "[Validate] TP Loss Across Timepoints: [2.42376208 2.50884199]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.77140492 0.57261123]\n",
      "Epoch [3/25]\n",
      "[Train] MAE Loss: 0.03664269025127093, TP Loss: 1.9868315756320953, MAE of Mem Caps Loss: 0.6168981466082797\n",
      "[Validate] MAE Loss Across Timepoints: [0.04740546 0.0519292 ]\n",
      "[Validate] TP Loss Across Timepoints: [2.08098078 2.24954033]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.48692937 0.57282064]\n",
      "Epoch [4/25]\n",
      "[Train] MAE Loss: 0.034000511684765415, TP Loss: 1.8562771012385686, MAE of Mem Caps Loss: 0.36301812311196285\n",
      "[Validate] MAE Loss Across Timepoints: [0.04517673 0.04910572]\n",
      "[Validate] TP Loss Across Timepoints: [1.95506847 2.08634806]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.7687678  0.68690156]\n",
      "Epoch [5/25]\n",
      "[Train] MAE Loss: 0.033013102257003386, TP Loss: 1.7916581146419048, MAE of Mem Caps Loss: 0.37865057515853306\n",
      "[Validate] MAE Loss Across Timepoints: [0.04308206 0.04658063]\n",
      "[Validate] TP Loss Across Timepoints: [1.72533643 1.85848558]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.04381411 0.89563404]\n",
      "Epoch [6/25]\n",
      "[Train] MAE Loss: 0.03152648930748304, TP Loss: 1.6915135242044925, MAE of Mem Caps Loss: 0.370247267433399\n",
      "[Validate] MAE Loss Across Timepoints: [0.04199826 0.04525867]\n",
      "[Validate] TP Loss Across Timepoints: [1.64376664 1.76044083]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [1.02953529 0.91168726]\n",
      "Epoch [7/25]\n",
      "[Train] MAE Loss: 0.031015902105718852, TP Loss: 1.6447917876144251, MAE of Mem Caps Loss: 0.3355060030199964\n",
      "[Validate] MAE Loss Across Timepoints: [0.0417289  0.04487864]\n",
      "[Validate] TP Loss Across Timepoints: [1.61658144 1.71709085]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94071973 0.81150463]\n",
      "Epoch [8/25]\n",
      "[Train] MAE Loss: 0.03094636236007015, TP Loss: 1.660998065272967, MAE of Mem Caps Loss: 0.3441864427217357\n",
      "[Validate] MAE Loss Across Timepoints: [0.04162637 0.04469293]\n",
      "[Validate] TP Loss Across Timepoints: [1.61794519 1.72137368]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.86071793 0.79894973]\n",
      "Epoch [9/25]\n",
      "[Train] MAE Loss: 0.030597892124205828, TP Loss: 1.663172475496928, MAE of Mem Caps Loss: 0.33986931886918953\n",
      "[Validate] MAE Loss Across Timepoints: [0.04171109 0.04484381]\n",
      "[Validate] TP Loss Across Timepoints: [1.63678265 1.74883294]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.85264724 0.85980236]\n",
      "Epoch [10/25]\n",
      "[Train] MAE Loss: 0.030614953332891066, TP Loss: 1.648087425529957, MAE of Mem Caps Loss: 0.36353383587935983\n",
      "[Validate] MAE Loss Across Timepoints: [0.04133983 0.0443028 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.54386556 1.61507189]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.8499872  0.79156202]\n",
      "Epoch [11/25]\n",
      "[Train] MAE Loss: 0.03041523036857446, TP Loss: 1.6363134883344173, MAE of Mem Caps Loss: 0.34070931282086364\n",
      "[Validate] MAE Loss Across Timepoints: [0.04139423 0.04437479]\n",
      "[Validate] TP Loss Across Timepoints: [1.59794593 1.69741786]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.86119597 0.78587058]\n",
      "Epoch [12/25]\n",
      "[Train] MAE Loss: 0.030398192039380472, TP Loss: 1.6738473139703274, MAE of Mem Caps Loss: 0.35146759342657297\n",
      "[Validate] MAE Loss Across Timepoints: [0.04133312 0.04420476]\n",
      "[Validate] TP Loss Across Timepoints: [1.58805108 1.67608869]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.81250342 0.7875549 ]\n",
      "Epoch [13/25]\n",
      "[Train] MAE Loss: 0.030107345338910817, TP Loss: 1.5854833188156288, MAE of Mem Caps Loss: 0.3418123993844338\n",
      "[Validate] MAE Loss Across Timepoints: [0.04110051 0.04402415]\n",
      "[Validate] TP Loss Across Timepoints: [1.57051539 1.65833199]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.84882258 0.78161612]\n",
      "Epoch [14/25]\n",
      "[Train] MAE Loss: 0.030251882690936326, TP Loss: 1.638121522963047, MAE of Mem Caps Loss: 0.33702097596745184\n",
      "[Validate] MAE Loss Across Timepoints: [0.0412024  0.04419525]\n",
      "[Validate] TP Loss Across Timepoints: [1.59941316 1.69403565]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.94124172 0.7289298 ]\n",
      "Epoch [15/25]\n",
      "[Train] MAE Loss: 0.030079763072232407, TP Loss: 1.5988501923779646, MAE of Mem Caps Loss: 0.36518209866306134\n",
      "[Validate] MAE Loss Across Timepoints: [0.04103098 0.04391692]\n",
      "[Validate] TP Loss Across Timepoints: [1.55565774 1.6371094 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.85845475 0.74309166]\n",
      "Epoch [16/25]\n",
      "[Train] MAE Loss: 0.029845563415437936, TP Loss: 1.6099404988189538, MAE of Mem Caps Loss: 0.3483572290271452\n",
      "[Validate] MAE Loss Across Timepoints: [0.04110634 0.04396637]\n",
      "[Validate] TP Loss Across Timepoints: [1.57821143 1.674245  ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.89919967 0.76877367]\n",
      "Epoch [17/25]\n",
      "[Train] MAE Loss: 0.02995732668787241, TP Loss: 1.6056687275568644, MAE of Mem Caps Loss: 0.3733323062596333\n",
      "[Validate] MAE Loss Across Timepoints: [0.04090132 0.0438096 ]\n",
      "[Validate] TP Loss Across Timepoints: [1.51046503 1.58556831]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.86039957 0.73242612]\n",
      "Epoch [18/25]\n",
      "[Train] MAE Loss: 0.029951278616984687, TP Loss: 1.6162962389489015, MAE of Mem Caps Loss: 0.3466326295669683\n",
      "[Validate] MAE Loss Across Timepoints: [0.04090485 0.04379293]\n",
      "[Validate] TP Loss Across Timepoints: [1.50520647 1.58423889]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.84624193 0.73178717]\n",
      "Epoch [19/25]\n",
      "[Train] MAE Loss: 0.029794398074348766, TP Loss: 1.585679299136003, MAE of Mem Caps Loss: 0.34413961871301435\n",
      "[Validate] MAE Loss Across Timepoints: [0.04089702 0.04385149]\n",
      "[Validate] TP Loss Across Timepoints: [1.54600883 1.6415745 ]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.79317005 0.75364554]\n",
      "Epoch [20/25]\n",
      "[Train] MAE Loss: 0.029697155797233185, TP Loss: 1.5967239466806253, MAE of Mem Caps Loss: 0.34695423127407626\n",
      "[Validate] MAE Loss Across Timepoints: [0.04078798 0.04361942]\n",
      "[Validate] TP Loss Across Timepoints: [1.51160073 1.58522701]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.87941503 0.74243525]\n",
      "Epoch [21/25]\n",
      "[Train] MAE Loss: 0.029782002388189236, TP Loss: 1.5711302121480306, MAE of Mem Caps Loss: 0.3513798640988792\n",
      "[Validate] MAE Loss Across Timepoints: [0.0407246  0.04349877]\n",
      "[Validate] TP Loss Across Timepoints: [1.50512981 1.56494272]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.74473665 0.7326377 ]\n",
      "Epoch [22/25]\n",
      "[Train] MAE Loss: 0.02965649953112006, TP Loss: 1.5953048932055631, MAE of Mem Caps Loss: 0.36043314875006643\n",
      "[Validate] MAE Loss Across Timepoints: [0.04060811 0.04338992]\n",
      "[Validate] TP Loss Across Timepoints: [1.48940897 1.53625703]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.83344334 0.83400587]\n",
      "Epoch [23/25]\n",
      "[Train] MAE Loss: 0.029608609558393558, TP Loss: 1.5824513730903467, MAE of Mem Caps Loss: 0.3526720602390071\n",
      "[Validate] MAE Loss Across Timepoints: [0.04066659 0.04347314]\n",
      "[Validate] TP Loss Across Timepoints: [1.49442995 1.52386951]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.96047384 0.75961826]\n",
      "Epoch [24/25]\n",
      "[Train] MAE Loss: 0.02978636311988036, TP Loss: 1.5936535527308782, MAE of Mem Caps Loss: 0.34509472592161206\n",
      "[Validate] MAE Loss Across Timepoints: [0.04082265 0.04364483]\n",
      "[Validate] TP Loss Across Timepoints: [1.54290354 1.62341893]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.84978555 0.77892197]\n",
      "Epoch [25/25]\n",
      "[Train] MAE Loss: 0.029543789817641178, TP Loss: 1.5687342723210653, MAE of Mem Caps Loss: 0.33987030937179613\n",
      "[Validate] MAE Loss Across Timepoints: [0.04073508 0.04360878]\n",
      "[Validate] TP Loss Across Timepoints: [1.54582334 1.61921263]\n",
      "[Validate] MAE of Mem Caps Across Timepoints: [0.7941159  0.71359763]\n",
      "\n",
      "epochs finished with time:1124.0422432422638\n",
      "\n",
      "Current memory usage: 2622.06 MB\n",
      "\n",
      "[Test] MAE Loss Across Timepoints: [0.04202422 0.04481659]\n",
      "[Test] TP Loss Across Timepoints: [3.61475434 3.31421002]\n",
      "[Test] MAE of Mem Caps Across Timepoints: [0.65925078 0.79731235]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "input_weights = (torch.rand((35, 1), dtype=torch.float64) * 2.0 - 1.0).to(device)\n",
    "\n",
    "indexes = range(args.num_folds)\n",
    "kfold = KFold(n_splits=args.num_folds, shuffle=True, random_state=manual_seed)\n",
    "dataset = dataset.to(device)\n",
    "actual_mem_caps = np.load('datasets/mem_caps_oasis_language.npy')\n",
    "f = 0\n",
    "\n",
    "for train, test in kfold.split(range(dataset.shape[0])):\n",
    "    print(\n",
    "            f'------------------------------------Fold [{f + 1}/{args.num_folds}]-----------------------------------------')\n",
    "    \n",
    "    train_data = dataset[train]\n",
    "    test_data = dataset[test]\n",
    "    train_mem_cap = actual_mem_caps[train]\n",
    "    test_mem_cap = actual_mem_caps[test]\n",
    "    \n",
    "    validation_split = int(0.8 * len(train_data))\n",
    "    train_subjects = train_data[:validation_split]\n",
    "    train_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "   \n",
    "    validation_subjects = train_data[validation_split:]\n",
    "    validation_mem_cap_subjects = train_mem_cap[:validation_split]\n",
    "\n",
    "    model = GConvGRUModel(device=device, input_weights=input_weights, input_scaling=1e-1).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "    mael = torch.nn.L1Loss().to(device)\n",
    "    tp = torch.nn.MSELoss().to(device)\n",
    "  \n",
    "    # Start measuring the epochs time\n",
    "    epochs_start = time.time()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        \n",
    "        print(f'Epoch [{epoch + 1}/{args.num_epochs}]')\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        # this is our loss for all the data\n",
    "        mae_loss_overall = []\n",
    "        tp_loss_overall = []\n",
    "        mae_mem_cap_overall = []\n",
    "        \n",
    "        # loop through the data batches\n",
    "        for data_id, data in enumerate(train_subjects):\n",
    "\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            mae_loss = 0\n",
    "            tp_loss = 0\n",
    "            mem_cap_loss = 0\n",
    "         \n",
    "            # loop through the time dependent adj matrices in the batches\n",
    "            for t in range(args.num_timepoints - 1):\n",
    "                pred, output_sig = model(data[t], X_train_res, y_train_res, X_test_res)\n",
    "                    \n",
    "                real = data[t + 1]\n",
    "        \n",
    "                mae_loss += mael(pred, real)\n",
    "\n",
    "                # Topological Loss\n",
    "                tp_loss += tp(pred.sum(dim=-1), real.sum(dim=-1))\n",
    "\n",
    "                # MAE between predicted graph's mem cap and actual graph's mem cap\n",
    "                predicted_mem_cap = compute_memory_capacity_vectorized(output_sig, y_test_res)\n",
    "                actual_mem_cap = torch.tensor(train_mem_cap_subjects[data_id, t + 1], requires_grad=True).to(device)\n",
    "                mem_cap_loss += mael(predicted_mem_cap, actual_mem_cap)\n",
    "\n",
    "    \n",
    "            # Calculate the total MAE Loss for the current batch\n",
    "            mae_loss = mae_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total TP Loss for the current batch\n",
    "            tp_loss = tp_loss / (args.num_timepoints - 1)\n",
    "\n",
    "            # Calculate the total MAE between Mem Cap Loss for the current batch\n",
    "            mem_cap_loss = mem_cap_loss / (args.num_timepoints - 1)\n",
    "            \n",
    "            # Append to the total MAE Loss\n",
    "            mae_loss_overall.append(mae_loss.item())\n",
    "            tp_loss_overall.append(tp_loss.item())\n",
    "            mae_mem_cap_overall.append(mem_cap_loss.item())\n",
    "            \n",
    "            total_loss = mae_loss + args.memcap_coef * mem_cap_loss \n",
    "            # Update the weights of the neural network\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        mae_loss_overall = np.mean(np.array(mae_loss_overall))\n",
    "        tp_loss_overall = np.mean(np.array(tp_loss_overall))\n",
    "        mae_mem_cap_overall = np.mean(np.array(mae_mem_cap_overall))\n",
    "        print(f\"[Train] MAE Loss: {mae_loss_overall}, TP Loss: {tp_loss_overall}, MAE of Mem Caps Loss: {mae_mem_cap_overall}\")\n",
    "    \n",
    "        avg_val_mae_loss, avg_val_tp_loss, avg_val_mae_mem_cap, _, _ = validation(model, validation_subjects, validation_mem_cap_subjects,\n",
    "                                                                                  X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "        print(f\"[Validate] MAE Loss Across Timepoints: {avg_val_mae_loss}\")\n",
    "        print(f\"[Validate] TP Loss Across Timepoints: {avg_val_tp_loss}\")\n",
    "        print(f\"[Validate] MAE of Mem Caps Across Timepoints: {avg_val_mae_mem_cap}\")\n",
    "\n",
    "    \n",
    "    epochs_end = time.time() - epochs_start\n",
    "    print()\n",
    "    print(f'epochs finished with time:{epochs_end}')\n",
    "    print()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(f\"Current memory usage: {process.memory_info().rss / 1024 ** 2:.2f} MB\")\n",
    "    print()\n",
    "    \n",
    "    avg_test_mae_loss, avg_test_tp_loss, avg_test_mem_cap, predicted, original = validation(model, test_data, test_mem_cap,\n",
    "                                                                                            X_train_res, y_train_res, X_test_res, y_test_res)\n",
    "    print(f\"[Test] MAE Loss Across Timepoints: {avg_test_mae_loss}\")\n",
    "    print(f\"[Test] TP Loss Across Timepoints: {avg_test_tp_loss}\")\n",
    "    print(f\"[Test] MAE of Mem Caps Across Timepoints: {avg_test_mem_cap}\")\n",
    "    np.save(args.save_path+f\"test_mae_losses/mae_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_tp_losses/tp_test_loss_fold_{f}\", avg_test_mae_loss)\n",
    "    np.save(args.save_path+f\"test_memcap_losses/memcap_test_loss_fold_{f}\", avg_test_mem_cap)\n",
    "    np.save(args.save_path+f\"test_predicted/predicted_fold_{f}\", predicted)\n",
    "    np.save(args.save_path+f\"test_original/original_fold_{f}\", original)\n",
    "\n",
    "    torch.save(model.state_dict(),\n",
    "               args.save_path +f'trained_models/model_fold_{f}')\n",
    "    f += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "90ooXFhVd5Ci",
    "v7zuUNtIu26b",
    "boAUzmyY1b45",
    "gCeqTVgMstrm",
    "VoaPdwAI_3OO",
    "cBsklrSsPUtm",
    "ke3Z16hUbTSE",
    "E77zvOJPlTul",
    "tY7gZyeQaHdO",
    "BDKGEEKpqE9-",
    "8KHFUzhADA6_",
    "2kUqdyWRj5qF",
    "tHprtfbUku3t",
    "5DL6MoT5xRkX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "0f5c6f72bc62c81ae52e96e9a3a4236b77333ef45d4cdc0c3574ebd317f415f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
